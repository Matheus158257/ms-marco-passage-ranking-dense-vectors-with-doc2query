{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"5_1_DOIS_MOD_TwoTowerPassageRanking_GoldPassages.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a6d2d20413744206a7dd8ada45306959":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_57bbaf6bdbb54239a904d8d92a7a6f51","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_652e7bbf75714f7bb50389744f9a7b80","IPY_MODEL_e6e0bca496ff4412af0c1ed96e8a15ef"]}},"57bbaf6bdbb54239a904d8d92a7a6f51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"652e7bbf75714f7bb50389744f9a7b80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b454a4c36a154526a144785d79ac4cc4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c3b83f4b88914c3c9339be4e6a427831"}},"e6e0bca496ff4412af0c1ed96e8a15ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_85870a8c2777415580aa80652f4cf971","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:08&lt;00:00, 53.2B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2ad83370f70c41a098c364ab550ab277"}},"b454a4c36a154526a144785d79ac4cc4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c3b83f4b88914c3c9339be4e6a427831":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"85870a8c2777415580aa80652f4cf971":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2ad83370f70c41a098c364ab550ab277":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d19686d41314c4482c989f1c0769d9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6a3653dffc5e4818a6d802e221c21b16","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_adf42b42b1564919843778d10cb664e4","IPY_MODEL_f33550fae2e64cba8de40f0ae167d0c0"]}},"6a3653dffc5e4818a6d802e221c21b16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"adf42b42b1564919843778d10cb664e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_387c5d95defd4e15816d1437edb410ef","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_be6c5f433c4742719e36012f67d5d96a"}},"f33550fae2e64cba8de40f0ae167d0c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_759b62d1450e4ed898afb02f05e7dee8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:06&lt;00:00, 68.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_55b6b4f160f14f4db334eb0349c0415e"}},"387c5d95defd4e15816d1437edb410ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"be6c5f433c4742719e36012f67d5d96a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"759b62d1450e4ed898afb02f05e7dee8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"55b6b4f160f14f4db334eb0349c0415e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a3b63b6f08384f2d9b2ed653e60cb6e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_14cd7b86917b4190bb16fa5862957c94","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7d3d4e82abae4bb09a8deba876200761","IPY_MODEL_142d7350ad4a46bcb7dc93ef7af3701c"]}},"14cd7b86917b4190bb16fa5862957c94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"7d3d4e82abae4bb09a8deba876200761":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8d221f5155084833a0a053583288fd9d","_dom_classes":[],"description":"Validation sanity check: 100%","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3971aac0499440d5934ba481ced7c14b"}},"142d7350ad4a46bcb7dc93ef7af3701c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3ae31b8c19be4d689ea4cc2dafe6c6a4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2/2 [03:27&lt;00:00, 110.03s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4b5da93049743efafc1b1074e307270"}},"8d221f5155084833a0a053583288fd9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3971aac0499440d5934ba481ced7c14b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3ae31b8c19be4d689ea4cc2dafe6c6a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e4b5da93049743efafc1b1074e307270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f74c1d04f90b4dc2b9fe44b5977a7618":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_778fbae4228e4a0e804ea37a4fd0f4c7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a72647e720c04631acd0eee023ce036f","IPY_MODEL_28b96195c1144d36badc44c7af1cdb86"]}},"778fbae4228e4a0e804ea37a4fd0f4c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":"row wrap","width":"100%","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":"inline-flex","left":null}},"a72647e720c04631acd0eee023ce036f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ce027b3811664486b17133af688a2962","_dom_classes":[],"description":"Training: ","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_76177fb6e8b445918766b94aab7e76d2"}},"28b96195c1144d36badc44c7af1cdb86":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0daa622494ca453e936f0f317a692a70","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/? [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a9a76b9b664346e492b29e657a49a95c"}},"ce027b3811664486b17133af688a2962":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"76177fb6e8b445918766b94aab7e76d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":"2","_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0daa622494ca453e936f0f317a692a70":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a9a76b9b664346e492b29e657a49a95c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4nwq1mO8urSf"},"source":["# Two Tower Passage Ranking applyed to MS MARCO\n","### Desenvolvido por Graziella Bonadia e Matheus Sasso"]},{"cell_type":"markdown","metadata":{"id":"K8OmUmmcY4eH","colab_type":"text"},"source":["## Modelo Escolhido"]},{"cell_type":"code","metadata":{"id":"XfUHB_NfY40K","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030522095,"user_tz":180,"elapsed":1311,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["#@title Configurações gerais\n","experiment_name = 'TwoTowerPassageRanking'  #@param {type:\"string\"}\n","model_name = 'bert-base-uncased'  #@param [\"bert-base-uncased\",\"bert-large-uncased\",\"albert-base-v2\"] {type:\"string\"}"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vmMbfJZKhrg6"},"source":["## Instalações Externas e Download dos dados"]},{"cell_type":"markdown","metadata":{"id":"i8wkyvepQKrc","colab_type":"text"},"source":["Instalação de pacotes"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0mXaMmG4cb-F","colab":{},"executionInfo":{"status":"ok","timestamp":1593030530953,"user_tz":180,"elapsed":10140,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["! pip install pytorch-lightning  --quiet\n","! pip install transformers  --quiet\n","! pip install ftfy --quiet"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZSndTSQ2S-J2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030539968,"user_tz":180,"elapsed":19132,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["%%capture\n","!wget  https://anaconda.org/pytorch/faiss-cpu/1.2.1/download/linux-64/faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n","!tar xvjf faiss-cpu-1.2.1-py36_cuda9.0.176_1.tar.bz2\n","!cp -r lib/python3.6/site-packages/* /usr/local/lib/python3.6/dist-packages/\n","!pip install mkl\n","#!apt install libomp-dev\n","#!python -m pip install --upgrade faiss faiss-gpu"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEBVE7tpQMut","colab_type":"text"},"source":["Recuperação de **funções auxiliares**"]},{"cell_type":"code","metadata":{"id":"Le6md-L6KCEJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030545941,"user_tz":180,"elapsed":25086,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["%%capture\n","!wget -nc https://raw.githubusercontent.com/Matheus158257/ms-marco-passage-ranking-dense-vectors-with-doc2query/master/read_ms_marco.py\n","!wget -nc https://raw.githubusercontent.com/Matheus158257/ms-marco-passage-ranking-dense-vectors-with-doc2query/master/read_ms_marco2.py\n","!wget -nc https://raw.githubusercontent.com/spacemanidol/MSMARCO/master/Ranking/Baselines/msmarco_eval.py"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AcKtS0FGQSEE","colab_type":"text"},"source":["Importando google Drive"]},{"cell_type":"code","metadata":{"id":"pUxNvlVwP11t","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593030545943,"user_tz":180,"elapsed":25068,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"dd009d85-7b89-4571-e090-e0975df9e72e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BME0zRhbQdTV","colab_type":"text"},"source":["Caminhos para os arquivos importandos"]},{"cell_type":"code","metadata":{"id":"vh4ag6NARSAJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030545945,"user_tz":180,"elapsed":25049,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["proj_dir = '/content/drive/My Drive/Mestrado/PLN/Projeto'#Matheus\n","data_base_dir = '/content/drive/My Drive/Mestrado/PLN/Projeto/Data/Vetores_Densos' #Matheus\n","# proj_dir = '/content/drive/My Drive/Projeto'#Matheus\n","# data_base_dir = '/content/drive/My Drive/Projeto/Data/Vetores_Densos' #Matheus\n","# proj_dir = '/content/drive/My Drive/Projeto'#Graziella\n","# data_base_dir = '/content/drive/My Drive/Projeto/Data/Vetores_Densos' #Graziella"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"DR8GTK8AYGho","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030677042,"user_tz":180,"elapsed":1542,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["#  Caminhos utilizados\n","inference_data_dev_top1000_path = data_base_dir + '/inference_data_dev_top1000.json'\n","qrels_dev_path = data_base_dir + '/collectionandqueries/qrels.dev.tsv'\n","queries_train_path = data_base_dir + '/collectionandqueries/queries.train.tsv'\n","queries_dev_path = data_base_dir + '/collectionandqueries/queries.dev.tsv'\n","queries_dev_small_path = data_base_dir + '/collectionandqueries/queries_dev_small.tsv'\n","qid_pid_nid_path = data_base_dir + '/qidpidnid/triples_ids_train.tsv'\n","queries_topk_path  = data_base_dir + '/top1_K/doc2query_onek.tsv'\n","\n","# Outros caminhos para importar\n","# t5_zip_path = data_base_dir + '/t5_base/model.ckpt-1004000'\n","# qrels_train_path = data_base_dir + '/collectionandqueries/qrels.train.tsv'\n","# qrels_dev_small_path = data_base_dir + '/collectionandqueries/qrels.dev.small.tsv'\n","# qrels_valid_2019_path = data_base_dir + '/collectionandqueries/qrels_valid_2019.tsv'\n","# collection_path = data_base_dir + '/collectionandqueries/collection.tsv'\n","# queries_eval_path = data_base_dir + '/collectionandqueries/queries.eval.tsv'\n","# queries_eval_small_path = data_base_dir + '/collectionandqueries/queries.eval.small.tsv'\n","# queries_dev_small_path = data_base_dir + '/collectionandqueries/queries_dev_small.tsv'\n","# queries_topk_folder  = data_base_dir + '/predicted_queries_topk_sampling'\n","# train_triples_small_path = data_base_dir + '/train_triples_small/triples_smalls_chunk_1.csv'\n","# inference_data100_path = data_base_dir +'/inference_data100.json'\n","# inference_data100_eval_2020_path = data_base_dir + '/inference_data100_eval_2020.json'"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"KHwNNtAihwub"},"source":["## Imports"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ob7qL6kUVjbu","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1593030548835,"user_tz":180,"elapsed":27906,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"5e31b145-a67f-46eb-d339-8fcd865d8158"},"source":["# General Libs\n","import gzip\n","import random\n","import pdb\n","import ftfy\n","import math\n","import logging\n","import functools\n","import traceback\n","import json\n","\n","\n","#Hardware Data\n","import psutil\n","from multiprocessing import cpu_count\n","import nvidia_smi\n","\n","#import das funções que vem do github\n","import collections\n","import sys\n","import os\n","from read_ms_marco import load_qrels\n","from read_ms_marco import load_queries\n","from read_ms_marco import load_collection\n","from read_ms_marco import load_doc2query\n","from read_ms_marco import load_triple\n","from read_ms_marco import load_txts_topk #load_txts_topk(folder,k=1,n=18,encoding=\"cp1252\")\n","from read_ms_marco import take_part\n","from read_ms_marco import reset_dict_keys\n","from read_ms_marco import train_val_test\n","import msmarco_eval\n","\n","#Data Sciens Libs\n","import numpy as np\n","import pandas as pd\n","\n","#Lightning\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","#Torch\n","import torch\n","from torch import Tensor\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","#Faiss\n","import faiss\n","\n","#Transformers\n","from transformers import BertTokenizer, BertModel\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","\n","#Generic Types\n","from typing import Dict\n","from typing import List\n","from typing import Tuple\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Failed to load GPU Faiss: No module named 'faiss.swigfaiss_gpu'\n","Faiss falling back to CPU-only.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"jdsJjJN6h1CP"},"source":["## Configurações Gerais"]},{"cell_type":"markdown","metadata":{"id":"UGdshy4qSd0T","colab_type":"text"},"source":["Imperdir Excesso de Logs (atenção, desabilita o pdb)"]},{"cell_type":"code","metadata":{"id":"zfeKDqtlSflf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030548840,"user_tz":180,"elapsed":27893,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["# logging.getLogger(\"transformers.configuration_utils\").setLevel(logging.WARNING)\n","# logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARNING)\n","# logging.getLogger(\"lightning\").setLevel(logging.WARNING)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1Tnw4gChSvGe","colab_type":"text"},"source":["Dados de CPU e GPU"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UGNTZKHrTM6l","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1593030548844,"user_tz":180,"elapsed":27880,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"c27854dd-2813-44e9-ee92-9cd862bd8bec"},"source":["nvidia_smi.nvmlInit()\n","handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n","print(\"\\nGetting Hardware Statatus...\\n\")\n","def hardware_stats():\n","    '''\n","    Returns a dict containing some hardware related stats\n","    '''\n","    res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)\n","    return {\"cpu\": str(psutil.cpu_percent()) + '%',\n","            \"mem\": str(psutil.virtual_memory().percent) + '%',\n","            \"gpu\": str(res.gpu) + '%',\n","            \"gpu_mem\": str(res.memory) + '%'}\n","\n","print(f\"Imports loaded succesfully. Current GPU: {torch.cuda.get_device_name(0)}, number of CPU cores: {cpu_count()}\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["\n","Getting Hardware Statatus...\n","\n","Imports loaded succesfully. Current GPU: Tesla P100-PCIE-16GB, number of CPU cores: 2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PKL4j-MahJhA"},"source":["Decorator para impedir quebra de memório recorrente"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AK-6S1u2hD93","colab":{},"executionInfo":{"status":"ok","timestamp":1593030548847,"user_tz":180,"elapsed":27867,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["#Impedir quebra de memória \n","# https://docs.fast.ai/troubleshoot.html#memory-leakage-on-exception\n","def gpu_mem_restore(func):\n","    @functools.wraps(func)\n","    def wrapper(*args, **kwargs):\n","        try:\n","            return func(*args, **kwargs)\n","        except:\n","            type, val, tb = sys.exc_info()\n","            traceback.clear_frames(tb)\n","            raise type(val).with_traceback(tb) from None\n","    return wrapper"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CXFdJz2KVeQw"},"source":["## Preparando Dados"]},{"cell_type":"markdown","metadata":{"id":"f17CCR_EolaG","colab_type":"text"},"source":["Extracao dos tsvs em dicionários"]},{"cell_type":"code","metadata":{"id":"5CqLp-rwraH4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":230},"executionInfo":{"status":"ok","timestamp":1593030549679,"user_tz":180,"elapsed":28684,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"3b0e28f7-8aba-4e86-bdcd-dbc2fea6ad4b"},"source":["original_queries_dev_small = load_queries(queries_dev_small_path)\n","original_queries_train = load_queries(queries_train_path)\n","original_queries_dev = load_queries(queries_dev_path)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Loading queries 0\n","Loading queries 0\n","Loading queries 100000\n","Loading queries 200000\n","Loading queries 300000\n","Loading queries 400000\n","Loading queries 500000\n","Loading queries 600000\n","Loading queries 700000\n","Loading queries 800000\n","Loading queries 0\n","Loading queries 100000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6OS2swlNvyqU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"ok","timestamp":1593030565855,"user_tz":180,"elapsed":44837,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"4ef4310e-cfa2-479f-e3c7-3c2df5340dde"},"source":["artificial_queries = load_doc2query(queries_topk_path)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Loading doc2query, doc 0\n","Loading doc2query, doc 1000000\n","Loading doc2query, doc 2000000\n","Loading doc2query, doc 3000000\n","Loading doc2query, doc 4000000\n","Loading doc2query, doc 5000000\n","Loading doc2query, doc 6000000\n","Loading doc2query, doc 7000000\n","Loading doc2query, doc 8000000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Et4ZBm21hk8j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593030565864,"user_tz":180,"elapsed":44832,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"9a4c7777-58d3-419b-cf10-c271c3b2385e"},"source":["artificial_queries['842095']"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'how do you know if a timing belt is replaced'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"XSssPOYuDehp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1593030682189,"user_tz":180,"elapsed":2313,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"75e97c26-5d5c-4151-db08-9b9dc4ac91b4"},"source":["triples = load_triple(qid_pid_nid_path)\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Loading triple 0\n","Loading triple 100000\n","Loading triple 200000\n","Loading triple 300000\n","Loading triple 400000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UMSQxM8Rq6uB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030686074,"user_tz":180,"elapsed":1061,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["debug_train, debug_val, debug_test = train_val_test(triples, 10, 5, 3)"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1rx9icuseIz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"status":"ok","timestamp":1593030687044,"user_tz":180,"elapsed":609,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"2b3a400f-6f09-4ff9-b03a-1d56dbd1d38b"},"source":["print(debug_train)\n","print(debug_val)\n","print(debug_test)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["{'0': ('1000094', '5399011', '4239068'), '1': ('1000684', '6133670', '54955'), '2': ('1000938', '5203582', '4737056'), '3': ('1001876', '2354621', '3473806'), '4': ('1002233', '5049159', '4679862'), '5': ('1002416', '6210209', '1474923'), '6': ('1003328', '3712662', '8581416'), '7': ('1003418', '5937401', '2702745'), '8': ('1003840', '4063719', '5433200'), '9': ('100386', '6182295', '588060')}\n","{'0': ('1003900', '4788874', '6105642'), '1': ('1003956', '3926579', '1317168'), '2': ('1004080', '5943981', '8247016'), '3': ('1004274', '4383463', '7283587'), '4': ('1004329', '3907674', '4171719')}\n","{'0': ('1004979', '2741708', '825582'), '1': ('1005307', '3480594', '8683170'), '2': ('1006123', '3773327', '2284569')}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c6BcbBdNP2Ap","colab_type":"text"},"source":["Dicionário que será utilizado em tempo de inferência"]},{"cell_type":"code","metadata":{"id":"R8FT5hIckNg8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030692228,"user_tz":180,"elapsed":3294,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["with open(inference_data_dev_top1000_path) as json_file:\n","    inference_dev_dict = json.load(json_file)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0Giyi5Rv_NIm"},"source":["## Carregando o dataset\n","\n","Nota: Evitar de olhar ao máximo o dataset de teste para não ficar enviseado no que será testado. Em aplicações reais, o dataset de teste só estará disponível no futuro, ou seja, é quando o usuário começa a testar o seu produto."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dvkPvS2QlbTm","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593030692231,"user_tz":180,"elapsed":1756,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"c5c6f858-e71c-4278-dd66-1b645f6c87cd"},"source":["tokenizer.encode_plus('we like pizza',\n","                      max_length =10,\n","                      pad_to_max_length=True,\n","                      add_special_tokens = True)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [101, 2057, 2066, 10733, 102, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]}"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZXnoYK5YXKgk"},"source":["Dataset Treino\n"]},{"cell_type":"code","metadata":{"id":"bHUDGusnrmHM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030692745,"user_tz":180,"elapsed":1349,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["class TrainDataset(Dataset):\n","    def __init__(self, triples, queries, artificial_queries,\n","                 tokenizer,max_length: int =100,training_step=False):\n","      \n","        self.triples = triples\n","        self.queries = queries\n","        self.artificial_queries = artificial_queries\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.triples)\n","\n","    def __getitem__(self, idx):\n","      # Numero(Chave)\n","        # import pdb;pdb.set_trace()\n"," \n","        qid, pid, nid = self.triples[str(idx)]\n","        \n","        #vetores densos - Texto(Valor)\n","        o_query = ftfy.fix_text(self.queries[qid])\n","        a_query_pos = ftfy.fix_text(self.artificial_queries[pid])\n","        a_query_neg = ftfy.fix_text(self.artificial_queries[nid])\n","\n","        #Tensores\n","        q_tok, q_mask, q_type = self.encode_plus(o_query)\n","        p_tok, p_mask, p_type = self.encode_plus(a_query_pos)\n","        n_tok, n_mask, n_type = self.encode_plus(a_query_neg)\n","\n","        return  (q_tok, q_mask, q_type,\n","                p_tok, p_mask, p_type,\n","                n_tok, n_mask, n_type,\n","                o_query, a_query_pos, a_query_neg)\n","\n","    def encode_plus(self, text):\n","        tokens = self.tokenizer.encode_plus(text=text, max_length=self.max_length,\n","                                       pad_to_max_length=True, add_special_tokens = True)\n","        \n","        \n","        tok =  torch.tensor(tokens[\"input_ids\"]).type(torch.long)\n","        mask = torch.tensor(tokens['attention_mask']).type(torch.long)\n","        tok_type = torch.tensor(tokens['token_type_ids']).type(torch.long)\n","\n","        return tok,mask,tok_type"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15SPvjcRJy2m","colab_type":"text"},"source":["Dataset Inferência"]},{"cell_type":"code","metadata":{"id":"HIcPdyBZJxe1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030695005,"user_tz":180,"elapsed":1186,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["class InferenceDataset(Dataset):\n","\n","    def __init__(self,dicts, queries,artificial_queries,\n","                 tokenizer,max_length: int =100,training_step=False):\n","        self.dicts = dicts\n","        self.queries = queries\n","        self.passages = artificial_queries\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","\n","    def __len__(self):\n","      return len(self.dicts)\n","\n","\n","    def __getitem__(self, idx):\n","\n","        qid, pids = self.dicts[str(idx)]\n","        o_query = ftfy.fix_text(self.queries[qid])\n","        passages = [ftfy.fix_text(self.passages[pid]) for pid in pids]\n","\n","        o_query_tok,o_query_mask = self.encode_plus(o_query) \n","        passages_tensors = [self.encode_plus(passage) for passage in passages] #retorna tuplas com token e mask [(tok,mask),(),(),()] , tok([[tensor()]][tensor()][tensor()][tensor()])\n","\n","        return  (qid,pids,o_query,passages,o_query_tok,o_query_mask,passages_tensors)\n","\n","    def encode_plus(self, text):\n","        tokens = self.tokenizer.encode_plus(text=text, max_length=self.max_length,\n","                                       pad_to_max_length=True, add_special_tokens = True)\n","        \n","        \n","        tok =  torch.tensor(tokens[\"input_ids\"]).type(torch.long)\n","        mask = torch.tensor(tokens['attention_mask']).type(torch.long)\n","        # tok_type = torch.tensor(tokens['token_type_ids']).type(torch.long)\n","\n","        return tok,mask"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"cloyt0tIwIiD"},"source":["## Testando o DataLoader"]},{"cell_type":"markdown","metadata":{"id":"SWiW0wZcOIcn","colab_type":"text"},"source":["### Treino"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZoKiQXCvwGrP","colab":{"base_uri":"https://localhost:8080/","height":976},"executionInfo":{"status":"ok","timestamp":1593030697057,"user_tz":180,"elapsed":1048,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"9b62839f-c69e-4428-c170-fa701e6ebba0"},"source":["dataset_debug = TrainDataset(\n","    triples =  debug_val,\n","    queries = original_queries_train,\n","    artificial_queries = artificial_queries,\n","    tokenizer=tokenizer,\n","    max_length=20)\n","\n","dataloader_debug = DataLoader(dataset_debug, batch_size=2, shuffle=True,num_workers=cpu_count())\n","\n","q_tok, q_mask, q_type,p_tok, p_mask, p_type,n_tok, n_mask, n_type,o_query, a_query_pos, a_query_neg = next(iter(dataloader_debug))\n","\n","        \n","print('original_query_token_ids:\\n', q_tok)\n","print('original_query_mask:\\n', q_mask)\n","print('original_query_token_type:\\n', q_type)\n","\n","print('positive_query_token_ids:\\n', p_tok)\n","print('positive_query_mask:\\n', p_mask)\n","print('positive_query_token_type:\\n', p_type)\n","\n","print('negative_query_token_ids:\\n', n_tok)\n","print('negative_query_mask:\\n', n_mask)\n","print('negative_query_token_type:\\n', n_type)\n","\n","\n","print('original_query_token_ids.shape:\\n', q_tok.shape)\n","print('original_query_mask.shape:\\n', q_mask.shape)\n","print('original_query_token_type.shape:\\n', q_type.shape)\n","\n","print('positive_query_token_ids.shape:\\n', p_tok.shape)\n","print('positive_query_mask.shape:\\n', p_mask.shape)\n","print('positive_query_token_type.shape:\\n', p_type.shape)\n","\n","print('negative_query_token_ids.shape:\\n', n_tok.shape)\n","print('negative_query_mask.shape:\\n', n_mask.shape)\n","print('negative_query_token_type.shape:\\n', n_type.shape)\n","\n","print(o_query)\n","print(a_query_pos)\n","print(a_query_neg)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["original_query_token_ids:\n"," tensor([[  101,  2073,  2001,  1996,  3212,  8515,  5033,  4224,  2902,   102,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  101,  2073,  2057,  2064,  2224, 10763,  2372,   102,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n","original_query_mask:\n"," tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","original_query_token_type:\n"," tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","positive_query_token_ids:\n"," tensor([[  101,  2040,  2001,  2141,  1999,  1996,  8515,  5033,   102,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  101, 10812,  6210,  2465,   102,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n","positive_query_mask:\n"," tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","positive_query_token_type:\n"," tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","negative_query_token_ids:\n"," tensor([[  101,  2054,  3417,  2079,  2017,  2202,  2013,  2430,  2637,   102,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n","        [  101,  2054,  2003, 10763,  9570,  2953,   102,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])\n","negative_query_mask:\n"," tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","negative_query_token_type:\n"," tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n","        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","original_query_token_ids.shape:\n"," torch.Size([2, 20])\n","original_query_mask.shape:\n"," torch.Size([2, 20])\n","original_query_token_type.shape:\n"," torch.Size([2, 20])\n","positive_query_token_ids.shape:\n"," torch.Size([2, 20])\n","positive_query_mask.shape:\n"," torch.Size([2, 20])\n","positive_query_token_type.shape:\n"," torch.Size([2, 20])\n","negative_query_token_ids.shape:\n"," torch.Size([2, 20])\n","negative_query_mask.shape:\n"," torch.Size([2, 20])\n","negative_query_token_type.shape:\n"," torch.Size([2, 20])\n","('where was the navy panama canal zone hospital', 'where we can use static members')\n","('who was born in the panama canal', 'anonymous definition class')\n","('what port do you take from central america', 'what is static constructor')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PDgT6GewOK4D","colab_type":"text"},"source":["### Inferência"]},{"cell_type":"markdown","metadata":{"id":"a645wScaOOHc","colab_type":"text"},"source":["Não vamos visualizar por ser muito grande"]},{"cell_type":"code","metadata":{"id":"qCtJjojQjzt-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030706397,"user_tz":180,"elapsed":6431,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":[" dataset = InferenceDataset(\n","    dicts = inference_dev_dict,\n","    queries = original_queries_dev_small,\n","    artificial_queries = artificial_queries,\n","    tokenizer=tokenizer,\n","    max_length=100\n",")\n","\n","dataloader_debug = DataLoader(dataset, batch_size=4, shuffle=False,num_workers=cpu_count())\n","qid,pids,o_query,passages,o_query_tok,o_query_mask,passages_tensors = next(iter(dataloader_debug))# passages_tensors -> lista de tuplas [(pd_tok1,pd_mask1),(pd_tok2,pd_mask2)...]"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hLBoX02TFuE9","colab_type":"text"},"source":["## Loss Funtion"]},{"cell_type":"markdown","metadata":{"id":"5CXi2NmEFuFD","colab_type":"text"},"source":["***Documentation:***  \n","https://github.com/facebookresearch/faiss/wiki/Getting-started\n","\n","***Motivation:***   \n","Dense Passage Retrieval for Open-Domain Question Answering\n","https://arxiv.org/abs/2004.04906"]},{"cell_type":"markdown","metadata":{"id":"XHTrYR4FOH9W","colab_type":"text"},"source":["Faiss Para Negativos como Positivos dos outros valores do Batch"]},{"cell_type":"code","metadata":{"id":"hBIiNVJrFuE-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030706399,"user_tz":180,"elapsed":4150,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["def faiss_loss(Query,Passage):\n","\n","     X = Query.cpu()\n","     Y = Passage.cpu()\n","     X = X.detach().numpy()\n","     Y = Y.detach().numpy()\n","\n","     d = np.size(X,1)      ##Acertar para torch                    # vector dimension\n","     batch_size = np.size(X,0)      ##Acertar para torch           # we want to see number of batch size nearest neighbors  \n","     k = batch_size                                                # Its possible to change this number, but for the sake of this project, it will remain the same number of the batch size\n","     index = faiss.IndexFlatL2(d)                                  # build the index\n","     index.add(Y)                                                  # add vectors to the index\n","\n","     D, I = index.search(X, k)                                     # search. D is the matriz of similarities and I is the index of the vector in matriz ordered by similarity\n","\n","     resgate = np.arange(batch_size)                               # retrieve index of queries\n","     resgate = resgate.reshape((batch_size,1))\n","\n","     # This is necessary if there is a more similar vector then the target vector in the batch. Not probable, though.\n","     R = I - resgate\n","     T = R==0\n","     F = R!=0\n","\n","    #  T = I==0\n","    #  F = I!=0  \n","                                                       \n","     mrr_ind = np.where(T == True)                                 # retrieve the rank from True matrix\n","     mrr_rank = mrr_ind[1] + 1                                     # adjust the rank to start in '1'\n","     mrr_inv = 1/mrr_rank                                          # inverse of rank\n","     MRR = np.sum(mrr_inv)/k                                       # \"Accuracy\"  indicator\n","     MRR = np.array(MRR)\n","\n","     MRR = torch.from_numpy(MRR).float().to(device)\n","\n","     D_exp = np.exp(D)                                             # exp of similarities matrix\n","     sim_pos = D_exp[T==True]                                      # retrieve the vector of similarities of the target, despite its order (counting as positive)\n","     sim_neg = np.sum(((F == True) * D_exp), axis = 1)             # retrieve the vector of similarities of all other vectors and sum (counting as negative)\n","\n","     loss = - np.log(sim_pos/(sim_pos+sim_neg))                    # loss\n","     loss = torch.from_numpy(loss).float().to(device)\n","     loss = torch.sum(loss)\n","     loss = Variable(loss, requires_grad=True)\n","\n","\n","     return loss, MRR"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"phi3VuBiViX0","colab_type":"text"},"source":["Faiss para ranqueamento"]},{"cell_type":"code","metadata":{"id":"xv-_NenYpXNz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030706400,"user_tz":180,"elapsed":2036,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["def get_similarity(Query,Passages):\n","     X = Query.cpu()\n","     Y = Passages.cpu()\n","     X = X.detach().numpy()\n","     Y = Y.detach().numpy()\n","    \n","     k = len(Y)\n","     dim = np.size(X,1)           ##Acertar para torch                   # vector dimension\n","     index = faiss.IndexFlatL2(dim)                                  # build the index\n","     index.add(Y)                                                  # add vectors to the index\n","\n","     D, I = index.search(X, k) \n","\n","\n","     return D[0], I[0]"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aF0gFskgYzvj","colab_type":"text"},"source":["## Hyperparâmetros"]},{"cell_type":"code","metadata":{"id":"3qmYDv8AFuDK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030711871,"user_tz":180,"elapsed":5532,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["#@title Hyperparâmetros\n","batch_size =  16#@param {type:\"integer\"}\n","max_epochs = 3 #@param {type:\"integer\"}\n","accumulate_grad_batches = 16  #@param {type:\"integer\"}\n","max_length =   128#@param {type:\"integer\"}\n","learning_rate = 5e-3  #@param {type:\"number\"}"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"4PzITdXlYnel","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030714595,"user_tz":180,"elapsed":1024,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["hyperparams = {'model':model_name,'tokenizer':tokenizer,'learning_rate':learning_rate,'batch_size':batch_size,'max_length':max_length,'accumulate_grad_batches':accumulate_grad_batches} "],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FjFuuz9Q4yR3","colab_type":"text"},"source":["## Datasets"]},{"cell_type":"code","metadata":{"id":"2KGl2EoSV3_z","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030715445,"user_tz":180,"elapsed":966,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["triples_train, _, _ = train_val_test(triples, 50000, 100, 100)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"tqJAVQqtZ6m0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030716835,"user_tz":180,"elapsed":755,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["dataset_train = TrainDataset(triples =  triples_train, queries = original_queries_train,\n","                          artificial_queries = artificial_queries,\n","                          tokenizer=tokenizer,\n","                          max_length=max_length)\n","dataset_val  = InferenceDataset(\n","              dicts = inference_dev_dict,\n","              queries = original_queries_dev,\n","              artificial_queries = artificial_queries,\n","              tokenizer=tokenizer,\n","              max_length=max_length)\n","                              \n","\n","dataset_test = InferenceDataset(\n","              dicts = inference_dev_dict,\n","              queries = original_queries_dev,\n","              artificial_queries = artificial_queries,\n","              tokenizer=tokenizer,\n","              max_length=max_length)\n","\n","train_dataloader = DataLoader(dataset_train, batch_size=batch_size,\n","                              shuffle=True, num_workers=4)\n","\n","val_dataloader = DataLoader(dataset_val, batch_size=batch_size, shuffle=False, \n","                            num_workers=4)\n","\n","test_dataloader = DataLoader(dataset_test, batch_size=batch_size,\n","                             shuffle=False, num_workers=4)"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Vo8oCnIGXntL"},"source":["## Criando o Two Tower Passage Ranking com Pytorch Lightning"]},{"cell_type":"code","metadata":{"id":"fnMjMOj-4-XL","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030718910,"user_tz":180,"elapsed":1015,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["class TwoTowerFineTuner(pl.LightningModule):\n","\n","    def __init__(self, \n","                 hyperparams,\n","                 train_dataloader, val_dataloader,\n","                 test_dataloader,\n","                 overfit=False):\n","      \n","        super(TwoTowerFineTuner, self).__init__()\n","        \n","        \n","        #---------- Definição do modelo\n","        self.tower1 = BertModel.from_pretrained(model_name)\n","        self.tower2 = BertModel.from_pretrained(model_name)\n","        \n","\n","        #---------- Hyperparametros\n","        self.tokenizer = hyperparams['tokenizer']\n","        self.learning_rate = hyperparams['learning_rate']\n","        self.batch_size = hyperparams['batch_size']\n","        self.max_length = hyperparams['max_length']\n","        self.overfit = overfit\n","\n","        #---------- Camadas\n","        self.num_final_dim = 128\n","        self.dropout = torch.nn.Dropout(self.tower1.config.hidden_dropout_prob)\n","        self.final_layer = torch.nn.Linear(self.tower1.config.hidden_size, self.num_final_dim)\n","\n","\n","        #---------- Carregamento datasets (Para eu poder variar self.max_length)\n","\n","        self._train_dataloader = train_dataloader\n","        self._val_dataloader = val_dataloader\n","        self._test_dataloader = test_dataloader\n","                    \n","\n","    def infer(self,batch):\n","\n","        qid,pids,o_query,passages,o_query_tok,o_query_mask,passages_tensors = batch\n","\n","\n","        batch_similarities = []\n","        batch_pids = []\n","        batch_qids = []\n","        MRR_batch =  np.array([])\n","        for i in range(0,len(qid)):\n","          o_query_toks_tensor = o_query_tok[i].view(1,-1) #1xL \n","          o_query_masks_tensor = o_query_mask[i].view(1,-1) #1 X L \n","          query_hat = self.forward(o_query_toks_tensor, o_query_masks_tensor,self.tower1)\n","          phs = []\n","          for tuple_tensor in passages_tensors: \n","            passage_tok = tuple_tensor[0][i].view(1,-1) #1XL \n","            passage_mask = tuple_tensor[1][i].view(1,-1)\n","            #passage_hat = self.forward(passage_tok, passage_mask, self.tower2)\n","            passage_hat = self.forward(passage_tok, passage_mask, self.tower1)\n","            phs.append(passage_hat[0])\n","          \n","          passage_hats = torch.stack([ph for ph in phs], dim=0)\n","          similarities, order = get_similarity(query_hat,passage_hats)#q = 1xL , p = 100 x L\n","          similarity_normalized = [np.float64(elem).item() for elem in similarities][::-1]#revrese\n","          order_list = [np.float64(elem).item() for elem in order]\n","          pids_phrase = [p[i] for p in pids]\n","          pids_ordered = [x for _,x in sorted(zip(order_list,pids_phrase))][::-1] #revrese\n","          qids = [qid[i]]*len(pids)\n","          \n","          MRR = np.sum(similarity_normalized)/len(pids)\n","          MRR_batch = np.append(MRR_batch,MRR)\n","\n","          batch_pids.append(pids_ordered)\n","          batch_qids.append(qids)\n","          batch_similarities.append(similarity_normalized)\n","\n","        mrr = torch.tensor(np.mean(MRR_batch))\n","        return mrr, batch_pids, batch_qids , batch_similarities\n","      \n","\n","    def forward(self, input_ids, attention_mask, model,token_type_ids=None):    #model\n","        _, pooled_output = model(input_ids, attention_mask)\n","        pooled_output = self.dropout(pooled_output)\n","        logits = self.final_layer(pooled_output)\n","\n","        return logits\n","    \n","\n","    def training_step(self, batch, batch_nb):\n","        # batch\n","        query_token_ids, query_attention_mask, query_token_type_ids, qpos_token_ids, qpos_attention_mask, qpos_token_type_ids, n_tok, n_mask, n_type,o_query, a_query_pos, a_query_neg = batch\n","        \n","        # fwd\n","        query_hat = self.forward(query_token_ids, query_attention_mask,self.tower1 ,query_token_type_ids)\n","        #passage_hat = self.forward(qpos_token_ids, qpos_attention_mask,self.tower2 ,qpos_token_type_ids)\n","        passage_hat = self.forward(qpos_token_ids, qpos_attention_mask,self.tower1 ,qpos_token_type_ids)\n","\n","\n","        loss, MRR = faiss_loss(query_hat,passage_hat)\n","        \n","        # logs\n","        tensorboard_logs = {'train_loss': loss}\n","        return {'loss': loss, 'log': tensorboard_logs}\n","\n","    def validation_step(self, batch, batch_nb): \n","        val_mrr, batch_pids, batch_qids , batch_similarities = self.infer(batch)\n","        return {'val_mrr': val_mrr}\n","        \n","    def validation_epoch_end(self, outputs):\n","        avg_val_mrr = torch.stack([x['val_mrr'] for x in outputs]).mean()\n","        tensorboard_logs = {'avg_val_mrr': avg_val_mrr}    \n","        return {'avg_val_mrr': avg_val_mrr,'progress_bar': tensorboard_logs}\n","\n","    def test_step(self, batch, batch_nb):\n","        \n","        test_mrr, batch_pids, batch_qids , batch_similarities = self.infer(batch)\n","        \n","        return {'test_mrr': test_mrr}\n","\n","    def test_epoch_end(self, outputs):\n","\n","        avg_test_mrr = torch.stack([x['test_mrr'] for x in outputs]).mean()\n","\n","        tensorboard_logs = {'avg_test_mrr': avg_test_mrr}\n","        return {'avg_test_mrr': avg_test_mrr, 'log': tensorboard_logs,\n","                'progress_bar': tensorboard_logs}\n","    \n","    def configure_optimizers(self):\n","        return torch.optim.Adam(\n","            [p for p in self.parameters() if p.requires_grad],\n","            lr=self.learning_rate, eps=1e-08)\n","\n","    def train_dataloader(self):\n","        return self._train_dataloader\n","\n","    def val_dataloader(self):\n","        return self._val_dataloader\n","\n","    def test_dataloader(self):\n","        return self._test_dataloader"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"F3SGQDjN8w5L","colab":{},"executionInfo":{"status":"aborted","timestamp":1593030566318,"user_tz":180,"elapsed":45135,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["# model = TwoTowerFineTuner(hyperparams, train_dataloader=train_dataloader,\n","#                       val_dataloader=val_dataloader,\n","#                       test_dataloader=test_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EaXoBX2Qza8I","colab":{},"executionInfo":{"status":"aborted","timestamp":1593030566318,"user_tz":180,"elapsed":45130,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["# sum([torch.tensor(x.size()).prod() for x in model.parameters() if x.requires_grad]) # trainable parameters"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DO44876io6hw","colab_type":"text"},"source":["## Etapas de avaliação do Lightning"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CDcbeDvO71VL"},"source":["### Testando rapidamente o modelo em treino, validação e teste com um batch"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P2f6OPLGQcBW","colab":{},"executionInfo":{"status":"aborted","timestamp":1593030566319,"user_tz":180,"elapsed":45127,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["# trainer = pl.Trainer(gpus=1, \n","#                      checkpoint_callback=False,  # Disable checkpoint saving.\n","#                      fast_dev_run=True)\n","# trainer.fit(model)\n","# trainer.test(model)\n","# del model  # Para não ter estouro de mémoria da GPU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ST1NXQ8NEj2","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593030566320,"user_tz":180,"elapsed":45123,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["# del model  # Para não ter estouro de mémoria da GPU\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"kS2bjddQu87g"},"source":["### Trabalhando no datasset todo\n","\n"]},{"cell_type":"code","metadata":{"id":"uQkBu5ArnpIg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":435,"referenced_widgets":["a6d2d20413744206a7dd8ada45306959","57bbaf6bdbb54239a904d8d92a7a6f51","652e7bbf75714f7bb50389744f9a7b80","e6e0bca496ff4412af0c1ed96e8a15ef","b454a4c36a154526a144785d79ac4cc4","c3b83f4b88914c3c9339be4e6a427831","85870a8c2777415580aa80652f4cf971","2ad83370f70c41a098c364ab550ab277","8d19686d41314c4482c989f1c0769d9c","6a3653dffc5e4818a6d802e221c21b16","adf42b42b1564919843778d10cb664e4","f33550fae2e64cba8de40f0ae167d0c0","387c5d95defd4e15816d1437edb410ef","be6c5f433c4742719e36012f67d5d96a","759b62d1450e4ed898afb02f05e7dee8","55b6b4f160f14f4db334eb0349c0415e","a3b63b6f08384f2d9b2ed653e60cb6e0","14cd7b86917b4190bb16fa5862957c94","7d3d4e82abae4bb09a8deba876200761","142d7350ad4a46bcb7dc93ef7af3701c","8d221f5155084833a0a053583288fd9d","3971aac0499440d5934ba481ced7c14b","3ae31b8c19be4d689ea4cc2dafe6c6a4","e4b5da93049743efafc1b1074e307270","f74c1d04f90b4dc2b9fe44b5977a7618","778fbae4228e4a0e804ea37a4fd0f4c7","a72647e720c04631acd0eee023ce036f","28b96195c1144d36badc44c7af1cdb86","ce027b3811664486b17133af688a2962","76177fb6e8b445918766b94aab7e76d2","0daa622494ca453e936f0f317a692a70","a9a76b9b664346e492b29e657a49a95c"]},"executionInfo":{"status":"ok","timestamp":1593030970760,"user_tz":180,"elapsed":248425,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"d21aac37-8ae4-4bc7-fd2c-dcf9ba948b71"},"source":["from pytorch_lightning.callbacks import ModelCheckpoint\n","\n","checkpoint_path = proj_dir + '/Data/Checkpoints_dense_DOIS_MOD/epoch=3.ckpt'\n"," \n","checkpoint_dir = os.path.dirname(os.path.abspath(checkpoint_path))\n","print(f'Files in {checkpoint_dir}: {os.listdir(checkpoint_dir)}')\n","print(f'Saving checkpoints to {checkpoint_dir}')\n","checkpoint_callback = ModelCheckpoint(filepath=checkpoint_dir,save_top_k=-1)  # Keeps all checkpoints.\n","\n","resume_from_checkpoint = None\n","if os.path.exists(checkpoint_path):\n","    print(f'Restoring checkpoint: {checkpoint_path}')\n","    resume_from_checkpoint = checkpoint_path\n","\n","\n","trainer = pl.Trainer(gpus=1,\n","                     max_epochs=max_epochs,\n","                     check_val_every_n_epoch=1,\n","                     accumulate_grad_batches= accumulate_grad_batches,\n","                     checkpoint_callback=checkpoint_callback,\n","                     resume_from_checkpoint=resume_from_checkpoint)\n","\n","\n","model = TwoTowerFineTuner(hyperparams, train_dataloader=train_dataloader,\n","                      val_dataloader=val_dataloader,\n","                      test_dataloader=test_dataloader)\n","\n","trainer.fit(model)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["GPU available: True, used: True\n","TPU available: False, using: 0 TPU cores\n","CUDA_VISIBLE_DEVICES: [0]\n"],"name":"stderr"},{"output_type":"stream","text":["Files in /content/drive/My Drive/Mestrado/PLN/Projeto/Data/Checkpoints_dense_DOIS_MOD: ['epoch=1.ckpt', 'epoch=2.ckpt', 'epoch=3.ckpt', 'results_1qid.txt', 'results.test_dev.txt', 'results.test.txt']\n","Saving checkpoints to /content/drive/My Drive/Mestrado/PLN/Projeto/Data/Checkpoints_dense_DOIS_MOD\n","Restoring checkpoint: /content/drive/My Drive/Mestrado/PLN/Projeto/Data/Checkpoints_dense_DOIS_MOD/epoch=3.ckpt\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6d2d20413744206a7dd8ada45306959","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d19686d41314c4482c989f1c0769d9c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  | Name        | Type      | Params\n","------------------------------------------\n","0 | tower1      | BertModel | 109 M \n","1 | tower2      | BertModel | 109 M \n","2 | dropout     | Dropout   | 0     \n","3 | final_layer | Linear    | 98 K  \n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a3b63b6f08384f2d9b2ed653e60cb6e0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\r"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f74c1d04f90b4dc2b9fe44b5977a7618","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iCSfrdIr-vf-","colab":{},"executionInfo":{"status":"aborted","timestamp":1593030566322,"user_tz":180,"elapsed":45096,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["# trainer.test(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GVBwIVwDpMj1","colab_type":"text"},"source":["## Colocando dados no formato do MRR@10"]},{"cell_type":"markdown","metadata":{"id":"hYSpFO3zZHNA","colab_type":"text"},"source":["### DEV"]},{"cell_type":"code","metadata":{"id":"eXgpkt1-kVDB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593030970765,"user_tz":180,"elapsed":245584,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}}},"source":["dataset_val2  = InferenceDataset(\n","              dicts = inference_dev_dict,\n","              queries = original_queries_dev,\n","              artificial_queries = artificial_queries,\n","              tokenizer=tokenizer,\n","              max_length=max_length)\n","                              \n","val_dataloader2 = DataLoader(dataset_val2, batch_size=1, shuffle=False,num_workers=4)"],"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nTpQo2pzT2C","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"error","timestamp":1593031627104,"user_tz":180,"elapsed":10074,"user":{"displayName":"Matheus Gustavo Alves Sasso","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3hBAk_xyvoNPG1oRcGua6jw923vKztFHNgbSr=s64","userId":"12802130788492198743"}},"outputId":"0f4f1a83-f6ee-46cd-9f8b-23227a79460d"},"source":["import math\n","mrr = {}\n","results_path = proj_dir + '/Data/Checkpoints_dense_DOIS_MOD/' + 'passo_intermediario.txt' \n","df_reaclass= pd.DataFrame(columns=['QID','PID','RANK'])\n","pdis = []\n","sims = []\n","qdis = []\n","with open(results_path, 'w') as text_file:\n","  for batch in val_dataloader2:\n","      qid,pids,o_query,passages,o_query_tok,o_query_mask,passages_tensors = batch\n","      o_query_tok = o_query_tok.to(device)\n","      o_query_mask = o_query_mask.to(device)\n","      passages_tensors = [(tuple_pasasge[0].to(device), tuple_pasasge[1].to(device)) for tuple_pasasge in  passages_tensors]\n","      batch_gpu = qid,pids,o_query,passages,o_query_tok,o_query_mask,passages_tensors\n","      _, batch_pids, batch_qids , batch_similarities = model.infer(batch_gpu)\n","      for pids, qids , similarities in zip(batch_pids, batch_qids , batch_similarities):\n","        ranks = [n+1 for n in range (0,len(qids))]\n","        for p, q, s, r in zip(pids, qids , similarities, ranks):\n","          try:\n","              mrr[q].append(p)\n","          except:\n","              mrr[q] = [p]\n","\n","          df_reaclass = df_reaclass.append(pd.Series([q,p,r], index=df_reaclass.columns), ignore_index=True)\n","          text_file.write(f\"{q} {p} {r} \\n\")\n","          # \n","          if r==10:\n","              break\n","      \n","      break    \n","      \n","        \n","    # max_iteration = len(passages_tensors)\n","    # num_iterations = math.ceil(max_iteration/10)\n","\n","    # for i in range(0,num_iterations):\n","    #   try:\n","    #     passages_tensors_aux =passages_tensors[i*10:(i+1)*10]\n","    #     pids_aux = pids[i*10:(i+1)*10]\n","    #   except:       \n","    #     passages_tensors_aux =passages_tensors[i*10:]\n","    #     pids_aux = pids[i*10:]\n","\n","\n","    #   batch_gpu = qid,pids_aux,o_query,passages,o_query_tok,o_query_mask,passages_tensors_aux\n","    #   _, batch_pids, batch_qids , batch_similarities = model.infer(batch_gpu)\n","    #   for pids, qids , similarities in zip(batch_pids, batch_qids , batch_similarities):\n","    #     ranks = [n+1 for n in range (0,len(qids))]\n","    #     for p, q, s, r in zip(pids, qids , similarities, ranks):\n","    #       pdis.append(p)\n","    #       qdis.append(q)\n","    #       sims.append(s)\n","\n","\n","    #   break\n","          # text_file.write(q + \" \" + \"Q0\" + \" \" + p + \" \" + str(r) + \" \" + str(s) + \" \" + runid + \"\\n\") \n","          # text_file.write(q + \" \" + \"Q0\" + \" \" + p + \" \" + str(r) + \" \" + str(s) + \" \" + runid + \"\\n\") \n","          # try:\n","          #   mrr[q].append(p)\n","          # except:\n","          #   mrr[q] = [p]\n","          # if r==10:\n","          #   break\n"],"execution_count":36,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-8dd313ffc72b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mpassages_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple_pasasge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple_pasasge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtuple_pasasge\u001b[0m \u001b[0;32min\u001b[0m  \u001b[0mpassages_tensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mbatch_gpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo_query\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpassages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo_query_tok\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo_query_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpassages_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_pids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_qids\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mpids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqids\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0msimilarities\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_pids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_qids\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_similarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mranks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-32-d3f9b86a743f>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mpassage_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m#passage_hat = self.forward(passage_tok, passage_mask, self.tower2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mpassage_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassage_tok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassage_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtower1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassage_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-32-d3f9b86a743f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, model, token_type_ids)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m#model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m         )\n\u001b[1;32m    736\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m             )\n\u001b[1;32m    410\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add cross attentions if we output attention weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1610\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.90 GiB total capacity; 14.84 GiB already allocated; 5.88 MiB free; 15.11 GiB reserved in total by PyTorch)"]}]},{"cell_type":"code","metadata":{"id":"AzDG5MR5yHWS","colab_type":"code","colab":{}},"source":["qrels_dev = load_qrels(qrels_dev_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7vhIMbkw14q0","colab_type":"code","colab":{}},"source":["msmarco_eval.compute_metrics(qrels_dev, mrr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iN8Go1TRsqaO","colab":{}},"source":["# compression_opts = dict(method='zip', archive_name='enpt_t5_results.csv') \n","# model.df_test.to_csv('enpt_t5_results.zip', index=False,compression=compression_opts)  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HPfpCGKHqZuD"},"source":["# Fim do Notebook"]},{"cell_type":"code","metadata":{"id":"GGei2F-Kr372","colab_type":"code","colab":{}},"source":["# qids = []\n","# pdis = []\n","# sims = []\n","# ranks = []\n","# runid = 'runid1'\n","# results_path = proj_dir + '/Data/Checkpoints_dense_DOIS_MOD/' + 'results.test.txt' \n","\n","# with open(results_path, 'w') as text_file:\n","#   for batch in val_dataloader:\n","#       qid,pids,o_query,passages,o_query_tok,o_query_mask,passages_tensors = batch\n","#       o_query_tok = o_query_tok.to(device)\n","#       o_query_mask = o_query_mask.to(device)\n","#       passages_tensors = [(tuple_pasasge[0].to(device), tuple_pasasge[1].to(device)) for tuple_pasasge in  passages_tensors]\n","#       batch_gpu = qid,pids,o_query,passages,o_query_tok,o_query_mask,passages_tensors\n","\n","      \n","#       _, batch_pids, batch_qids , batch_similarities = model.infer(batch_gpu)\n","#       for pids, qids , similarities in zip(batch_pids, batch_qids , batch_similarities):\n","#         ranks = [i+1 for i in range (0,len(qids))]\n","#         for p, q, s, r in zip(pids, qids , similarities, ranks):\n","#           # text_file.write(q + \" \" + \"Q0\" + \" \" + p + \" \" + str(r) + \" \" + str(s) + \" \" + runid + \"\\n\") \n","#           text_file.write(f\"{q} {p} {r} \\n\")\n","\n","#           if r==10:\n","#             break\n","\n"],"execution_count":null,"outputs":[]}]}