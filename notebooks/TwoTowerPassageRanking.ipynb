{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4nwq1mO8urSf"
   },
   "source": [
    "# Two Tower Passage Ranking applyed to MS MARCO\n",
    "### Desenvolvido por Graziella Bonadia e Matheus Sasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Configurações gerais\n",
    "experiment_name = 'TwoTowerPassageRanking'  #@param {type:\"string\"}\n",
    "model_name = 'bert-base-uncased'  #@param [\"bert-base-uncased\",\"bert-large-uncased\",\"albert-base-v2\"] {type:\"string\"}\n",
    "batch_size =  4#@param {type:\"integer\"}\n",
    "max_epochs = 3 #@param {type:\"integer\"}\n",
    "accumulate_grad_batches = 16  #@param {type:\"integer\"}\n",
    "max_length = 100  #@param {type:\"integer\"}\n",
    "learning_rate = 5e-3  #@param {type:\"number\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformers\n",
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {'model':model,'tokenizer':tokenizer,'learning_rate':learning_rate,'batch_size':batch_size,'max_length':max_length,'accumulate_grad_batches':accumulate_grad_batches} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eu estiver LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkup_dataframe_path = 'C:\\\\Users\\\\Matheus\\\\Desktop\\\\Pós Graduação\\\\NLP\\\\Projeto\\\\Vetores Densos\\\\notebooks\\\\checkup_dataframe.zip'\n",
    "checkup_dataframe_dir = 'C:\\\\Users\\\\Matheus\\\\Desktop\\\\Pós Graduação\\\\NLP\\\\Projeto\\\\Vetores Densos\\\\notebooks'\n",
    "model_checkpoint_path = 'C:\\\\Users\\\\Matheus\\\\Desktop\\\\Pós Graduação\\\\NLP\\\\Projeto\\\\Vetores Densos\\\\checkpoint docTTTTTquery\\\\model.ckpt-1004000'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmMbfJZKhrg6"
   },
   "source": [
    "## Instalações Externas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 996
    },
    "colab_type": "code",
    "id": "0mXaMmG4cb-F",
    "outputId": "513ec882-513b-4a1e-e1bd-ce11b4e5c18b"
   },
   "outputs": [],
   "source": [
    "# ! pip install pytorch-lightning  --quiet\n",
    "# ! pip install transformers  --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a utilizaçõ de TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "# !python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KHwNNtAihwub"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ob7qL6kUVjbu",
    "outputId": "d90668d1-6ea4-4f74-e0eb-075e06423914"
   },
   "outputs": [],
   "source": [
    "# Importar todos os pacotes de uma só vez para evitar duplicados ao longo do notebook.\n",
    "\n",
    "# General Libs\n",
    "import gzip\n",
    "import os\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "#Hardware Data\n",
    "from multiprocessing import cpu_count\n",
    "import psutil\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "\n",
    "# #Drive\n",
    "# from google.colab import drive\n",
    "\n",
    "#Data Sciens Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TORCH XLA - TPU\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "#Generic Types\n",
    "from typing import Dict\n",
    "from typing import List\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdsJjJN6h1CP"
   },
   "source": [
    "## Configurações Gerais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBI0TjTj-svt"
   },
   "source": [
    "Definição de variáveis Globais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FgW-boJLU0wU"
   },
   "outputs": [],
   "source": [
    "# Configurações gerais\n",
    "accumulate_grad_batches = 16\n",
    "# Important: Fix seeds so we can replicate results\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "# np.random.seed(seed)\n",
    "torch.random.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fs5GhqmMTNNS"
   },
   "source": [
    "DICA para modelos reais: Um modelo otimizado deve manter o uso de GPU próximo a 100% durante o treino.\n",
    "Vamos utilizar a bilioteca abaixo para monitorar isso. Note que no modelo simples utilizado aqui o uso não vai chegar a 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce 920M\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(GPUs[0].name)\n",
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(dev)\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "UGNTZKHrTM6l",
    "outputId": "ca9f2234-9a37-4836-8a85-30c1c77bfa05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Lightning Version: 0.7.6\n",
      "Imports loaded succesfully.  number of CPU cores: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pytorch Lightning Version: {pl.__version__}\")\n",
    "\n",
    "def hardware_stats():\n",
    "    '''\n",
    "    Returns a dict containing some hardware related stats\n",
    "    '''\n",
    "\n",
    "    return {\"cpu\": str(psutil.cpu_percent()) + '%',\n",
    "            \"mem\": str(psutil.virtual_memory().percent) + '%',\n",
    "            \"gpu\": str([gpu.name for gpu in GPUs]) + '%'}\n",
    "\n",
    "# print(f\"Imports loaded succesfully. Current GPU: {torch.cuda.get_device_name(0)}, number of CPU cores: {cpu_count()}\")\n",
    "print(f\"Imports loaded succesfully.  number of CPU cores: {cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kcJXr5p3fZ1_"
   },
   "source": [
    "Quadro da NVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "sh3eqs2OfXmz",
    "outputId": "8e57f5c7-0e67-4aeb-809d-5b8cc5ed4b1e"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKL4j-MahJhA"
   },
   "source": [
    "Decorator para impedir quebra de memório recorrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AK-6S1u2hD93"
   },
   "outputs": [],
   "source": [
    "#Impedir quebra de memória \n",
    "# https://docs.fast.ai/troubleshoot.html#memory-leakage-on-exception\n",
    "import functools, traceback\n",
    "def gpu_mem_restore(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = sys.exc_info()\n",
    "            traceback.clear_frames(tb)\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ETfkvMGl4JA1"
   },
   "source": [
    "Iremos salvar os checkpoints (pesos do modelo) no google drive, para que possamos continuar o treino de onde paramos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "J-Co8U6O4Gl3",
    "outputId": "fdc586dc-b01c-46d1-b7af-95ddeb4af70f"
   },
   "outputs": [],
   "source": [
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CXFdJz2KVeQw"
   },
   "source": [
    "## Preparando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gHMi_Kq65fPM"
   },
   "source": [
    "Download do dataset de dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "2wbnfzst5O3k",
    "outputId": "8165e14a-682d-40e9-d1c5-5252631d3ac8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' nÆo ‚ reconhecido como um comando interno\n",
      "ou externo, um programa oper vel ou um arquivo em lotes.\n",
      "tar: Error opening archive: Failed to open 'index-msmarco-passage-20191117-0ed488.tar.gz'\n"
     ]
    }
   ],
   "source": [
    "!wget https://git.uwaterloo.ca/jimmylin/anserini-indexes/raw/master/index-msmarco-passage-20191117-0ed488.tar.gz\n",
    "!tar xvfz index-msmarco-passage-20191117-0ed488.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Giyi5Rv_NIm"
   },
   "source": [
    "## Carregando o dataset\n",
    "\n",
    "Criaremos uma divisão de treino (100k pares) e val (5k pares) artificialmente.\n",
    "\n",
    "Nota: Evitar de olhar ao máximo o dataset de teste para não ficar enviseado no que será testado. Em aplicações reais, o dataset de teste só estará disponível no futuro, ou seja, é quando o usuário começa a testar o seu produto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(checkup_dataframe_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(checkup_dataframe_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_queries  = pd.read_csv(checkup_dataframe_dir + 'checkup_dataframe.csv') \n",
    "df_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "dvkPvS2QlbTm",
    "outputId": "7298925e-9240-4ee0-f5a7-ac7973ebba65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'input_ids': [62, 114, 6871, 0, 0, 0, 0, 0, 0, 0],\n",
       " 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus('we like pizza',\n",
    "                      max_length =10,\n",
    "                      pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZXnoYK5YXKgk"
   },
   "source": [
    "Criando Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OMen-JFKLFCb"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, text: List[Tuple[str]], tokenizer, max_length: int = 100,training_step=False):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = text\n",
    "        self.max_length = max_length\n",
    "        self.training_step = training_step\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text_pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.text.iloc[idx]\n",
    "        original_query = text['ORIGINAL_QUERY']\n",
    "        positive_query =  text['POSITIVE_QUERY']\n",
    "        negative_query =  text['NEGATIVE_QUERY']\n",
    " \n",
    "        # Original Query\n",
    "        original_query_encode = f\"{original_query} {tokenizer.eos_token}\"\n",
    "        original_query_encode = self.encoder_plus(original_query_encode,self.max_length)\n",
    "        original_query_token_ids = original_query_encode['input_ids']\n",
    "        original_query_mask = original_query_encode['attention_mask']\n",
    "        original_query_token_ids = torch.tensor(original_query_token_ids).type(torch.long)\n",
    "        original_query_mask = torch.tensor(original_query_mask).type(torch.long)\n",
    "                               \n",
    "                               \n",
    "        # Positonal Query\n",
    "        positive_query_encode = f\"{positive_query} {tokenizer.eos_token}\"\n",
    "        positive_query_encode = self.encoder_plus(original_query_encode,self.max_length)\n",
    "        positive_query_token_ids = positive_query_encode['input_ids']\n",
    "        positive_query_mask = positive_query_encode['attention_mask']\n",
    "        positive_query_token_ids = torch.tensor(positive_query_token_ids).type(torch.long)\n",
    "        positive_query_mask = torch.tensor(positive_query_mask).type(torch.long)\n",
    "                               \n",
    "        \n",
    "        # Negative Query\n",
    "        negative_query_encode = f\"{negative_query} {tokenizer.eos_token}\"\n",
    "        negative_query_encode = self.encoder_plus(original_query_encode,self.max_length)\n",
    "        negative_query_token_ids = negative_query_encode['input_ids']\n",
    "        negative_query_mask = negative_query_encode['attention_mask']\n",
    "        negative_query_token_ids = torch.tensor(negative_query_token_ids).type(torch.long)\n",
    "        negative_query_mask = torch.tensor(negative_query_mask).type(torch.long)\n",
    "        \n",
    "        \n",
    "        return (original_query_token_ids,original_query_mask,positive_query_token_ids,\n",
    "                positive_query_mask,negative_query_token_ids,negative_query_mask,\n",
    "                original_query,positive_query,negative_query)\n",
    "    \n",
    "    def encoder_plus(self,text,L):\n",
    "      return self.tokenizer.encode_plus(text,\n",
    "                                        max_length = L,\n",
    "                                        pad_to_max_length=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cloyt0tIwIiD"
   },
   "source": [
    "## Testando o DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "colab_type": "code",
    "id": "ZoKiQXCvwGrP",
    "outputId": "4ee24b0b-6ede-4428-bb99-34e2734ec0d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_token_ids:\n",
      " tensor([[13959,  1566,    12, 21076,    10,    62,   114,  6871,     1,     0,\n",
      "             0,     0,     0,     0,     0]])\n",
      "source_mask:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]])\n",
      "target_token_ids:\n",
      " tensor([[   3,   15,   76,  281,    7,  235,   20, 6871,    1,    0]])\n",
      "target_mask:\n",
      " tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])\n",
      "Source Word:\n",
      " we like pizza\n",
      "Target Word:\n",
      " eu gosto de pizza\n",
      "source_token_ids.shape: torch.Size([1, 15])\n",
      "source_mask.shape: torch.Size([1, 15])\n",
      "target_token_ids.shape: torch.Size([1, 10])\n",
      "target_mask.shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "text = df_train[:10]\n",
    "\n",
    "print(text)\n",
    "\n",
    "print(50*'-')\n",
    "\n",
    "dataset_debug = MyDataset(\n",
    "    text=text,\n",
    "    tokenizer=hyperparams['tokenizer'],\n",
    "    max_length=hyperparams['max_length'])\n",
    "\n",
    "dataloader_debug = DataLoader(dataset_debug, batch_size=10, shuffle=True,num_workers=cpu_count())\n",
    "\n",
    "original_query_token_ids,original_query_mask,positive_query_token_ids,\n",
    "positive_query_mask,negative_query_token_ids,negative_query_mask,\n",
    "original_query,positive_query,negative_query = next(iter(dataloader_debug))\n",
    "\n",
    "        \n",
    "print('original_query_token_ids:\\n', original_query_token_ids)\n",
    "print('original_query_mask:\\n', original_query_mask)\n",
    "print('positive_query_token_ids:\\n', positive_query_token_ids)\n",
    "print('positive_query_mask:\\n', positive_query_mask)\n",
    "print('negative_query_token_ids:\\n', negative_query_token_ids)\n",
    "print('negative_query_mask:\\n', negative_query_mask)\n",
    "\n",
    "\n",
    "print('original_query_token_ids.query:\\n', original_query_token_ids.query)\n",
    "print('original_query_mask.query:\\n', original_query_mask.query)\n",
    "print('positive_query_token_ids.query:\\n', positive_query_token_ids.query)\n",
    "print('positive_query_mask.query:\\n', positive_query_mask.query)\n",
    "print('negative_query_token_ids.query:\\n', negative_query_token_ids.query)\n",
    "print('negative_query_mask.query:\\n', negative_query_mask.query)\n",
    "\n",
    "\n",
    "print(original_query)\n",
    "print(positive_query)\n",
    "print(negative_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Funtion example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_document_passages():\n",
    "    '''\n",
    "    Implamentation\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAISS example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/facebookresearch/faiss/wiki/Getting-started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "d = 64                           # dimension\n",
    "nb = 100000                      # database size\n",
    "nq = 10000                       # nb of queries\n",
    "np.random.seed(1234)             # make reproducible\n",
    "xb = np.random.random((nb, d)).astype('float32')\n",
    "xb[:, 0] += np.arange(nb) / 1000.\n",
    "xq = np.random.random((nq, d)).astype('float32')\n",
    "xq[:, 0] += np.arange(nq) / 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building an index and adding the vectors to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss                   # make faiss available\n",
    "index = faiss.IndexFlatL2(d)   # build the index\n",
    "print(index.is_trained)\n",
    "index.add(xb)                  # add vectors to the index\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4                          # we want to see 4 nearest neighbors\n",
    "D, I = index.search(xb[:5], k) # sanity check\n",
    "print(I)\n",
    "print(D)\n",
    "D, I = index.search(xq, k)     # actual search\n",
    "print(I[:5])                   # neighbors of the 5 first queries\n",
    "print(I[-5:]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vo8oCnIGXntL"
   },
   "source": [
    "## Criando o Two Tower Passage Ranking com Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jg-hZEktbvnr"
   },
   "outputs": [],
   "source": [
    "class TwoTowerFineTunwer(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, \n",
    "                 hyperparams,\n",
    "                 all_data,\n",
    "                 use_tpu = False,\n",
    "                 overfit=False):\n",
    "      \n",
    "        super(TwoTowerFineTunwer, self).__init__()\n",
    "        \n",
    "        \n",
    "        #---------- Definição do modelo\n",
    "        tower1 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        tower2 = BertModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "\n",
    "        #---------- Hyperparametros\n",
    "        self.tokenizer = hyperparams['tokenizer']\n",
    "        self.learning_rate = hyperparams['learning_reate']\n",
    "        self.batch_size = hyperparams['batch_size']\n",
    "        self.source_max_length = hyperparams['max_length']\n",
    "        self.overfit = overfit\n",
    "\n",
    "\n",
    "        #---------- Carregamento datasets (Para eu poder variar self.max_length)\n",
    "        if overfit:\n",
    "          self.train_dataset = MyDataset(all_data[0], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n",
    "          self.valid_dataset = MyDataset(all_data[0], tokenizer=self.tokenizer, source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n",
    "          self.test_dataset =   MyDataset(all_data[0], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n",
    "        else:\n",
    "          self.train_dataset = MyDataset(all_data[0], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n",
    "          self.valid_dataset = MyDataset(all_data[1], tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n",
    "          self.test_dataset = MyDataset(all_data[2],  tokenizer=self.tokenizer,source_max_length = self.source_max_length, target_max_length =  self.target_max_length)\n",
    "        \n",
    "        \n",
    "        #---------- Loss Function\n",
    "        self.loss_funtion = criterion\n",
    "            \n",
    "\n",
    "        #---------- Algorythim step\n",
    "        self.training = True\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, source_token_ids, source_mask, target_token_ids=None,\n",
    "                target_mask=None):\n",
    "        \n",
    "        # outputs[0] --> Valor bruto, shape []\n",
    "        # outputs[1] -->  shape [B,L,32128]\n",
    "        # outputs[2] -->  shape [B,36,512]\n",
    "\n",
    "        if self.training:\n",
    "            outputs_tower1 = self.tower1(input_ids=source_token_ids,attention_mask=source_mask,lm_labels=target_token_ids)\n",
    "            outputs_tower2 = self.tower2(input_ids=source_token_ids,attention_mask=source_mask,lm_labels=target_token_ids)\n",
    "            \n",
    "            loss = loss_document_passages(outputs_tower1,outputs_tower2)# for explícito no mini-batch\n",
    "            \n",
    "            return loss\n",
    "        else:    \n",
    "            \n",
    "            # FAISS ONE QUERY\n",
    "            \n",
    "            \n",
    "            # FAISS SEARCH\n",
    "            D, I = index.search(xq, k) \n",
    "           \n",
    "        \n",
    "        \n",
    "            return nucleous_sampling_output\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # batch\n",
    "        source_token_ids, source_mask, target_token_ids, target_mask, _, _ = batch\n",
    "         \n",
    "        # fwd\n",
    "        self.training = True\n",
    "        loss = self.forward(source_token_ids, source_mask, target_token_ids)\n",
    "\n",
    "        # What to log\n",
    "        tensorboard_logs = {'loss': loss}\n",
    "\n",
    "        # Stats to be printed on TQDM bar\n",
    "        tqdm_dict = hardware_stats()\n",
    "\n",
    "\n",
    "        return {'loss': loss, 'log': tensorboard_logs, 'progress_bar': tqdm_dict}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "           \n",
    "            \n",
    "\n",
    "        #ISSO AQUI DA ESTRANHO, EU DEVERIA PEGAR PARA CADA VALOR DO BATCH E NÂO PARA A POSIÇÂO 0\n",
    "\n",
    "        # batch\n",
    "        self.training = False\n",
    "        source_token_ids, source_mask, target_token_ids, target_mask, original_source, original_target = batch\n",
    "        original_source, original_target = original_source[0], original_target[0]# Quando a string passa pelo data loader ele coloca como tupla: ('exemplo',)\n",
    "\n",
    "        # scoring\n",
    "        nucleous_sampling_output = self.forward(source_token_ids, source_mask)# Ja são os ids mas entre dois [[]]\n",
    "        generated_target = self.tokenizer.decode(nucleous_sampling_output[0], skip_special_tokens=False)\n",
    "        bleu_score = sacrebleu.corpus_bleu([generated_target], [[original_target]]).score\n",
    "        \n",
    "        #Adicionando elementos ao dataframe\n",
    "        self.df_valid = self.df_valid.append(pd.Series([original_source,original_target,generated_target,bleu_score], index=self.df_valid.columns ), ignore_index=True)\n",
    "\n",
    "\n",
    "        # Stats to be printed on TQDM bar\n",
    "        tqdm_dict = hardware_stats()\n",
    "\n",
    "        return {'val_bleu': bleu_score, 'progress_bar': tqdm_dict}\n",
    "\n",
    "    def test_step(self, batch, batch_nb):\n",
    "        # batch\n",
    "        self.training = False\n",
    "        source_token_ids, source_mask, target_token_ids, target_mask, original_source, original_target = batch\n",
    "        original_source, original_target = original_source[0], original_target[0]# Quando a string passa pelo data loader ele coloca como tupla: ('exemplo',)\n",
    "       \n",
    "        # scoring\n",
    "        nucleous_sampling_output = self.forward(source_token_ids, source_mask)\n",
    "        generated_target = self.tokenizer.decode(nucleous_sampling_output[0], skip_special_tokens=False)\n",
    "        bleu_score = sacrebleu.corpus_bleu([generated_target], [[original_target]]).score\n",
    "        \n",
    "        #Adicionando elementos ao dataframe\n",
    "        self.df_test = self.df_test.append(pd.Series([original_source,original_target,generated_target,bleu_score], index=self.df_test.columns),ignore_index=True)\n",
    "\n",
    "        # Stats to be printed on TQDM bar\n",
    "        tqdm_dict = hardware_stats()\n",
    "\n",
    "        return {'test_bleu': bleu_score, 'progress_bar': tqdm_dict}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_bleu = sum([x['val_bleu'] for x in outputs]) / len(outputs)\n",
    "\n",
    "        tensorboard_logs = {'avg_val_bleu': avg_bleu}\n",
    "        \n",
    "        return {'avg_val_bleu': avg_bleu, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        avg_bleu = sum([x['test_bleu'] for x in outputs]) / len(outputs)\n",
    "\n",
    "        tensorboard_logs = {'avg_test_bleu': avg_bleu}\n",
    "        \n",
    "        return {'avg_test_bleu': avg_bleu, 'progress_bar': tensorboard_logs}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(\n",
    "            [p for p in self.parameters() if p.requires_grad],\n",
    "            lr=self.learning_rate, eps=1e-08)\n",
    "    \n",
    "    \n",
    "    def check_sampler(dataset):\n",
    "        #---------- TPU Use\n",
    "        if this.use_tpu:\n",
    "            sampler = None\n",
    "        else: \n",
    "            sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "                dataset,\n",
    "                num_replicas=xm.xrt_world_size(),\n",
    "                rank=xm.get_ordinal(),\n",
    "                shuffle=True\n",
    "            )\n",
    "        return sampler\n",
    "\n",
    "    @gpu_mem_restore\n",
    "    def train_dataloader(self):\n",
    "        shuffle = False if self.overfit else True\n",
    "        sampler = check_sampler(self.train_dataset)\n",
    "        return DataLoader(self.train_dataset,sampler, batch_size=self.batch_size, shuffle=shuffle,num_workers=cpu_count())\n",
    "    \n",
    "    @gpu_mem_restore\n",
    "    def val_dataloader(self):\n",
    "        sampler = check_sampler(self.valid_dataset)\n",
    "            #FAISS INDEX\n",
    "            #EP para todas as passagens offline\n",
    "            index = faiss.IndexFlatL2(d)   # build the index\n",
    "            print(index.is_trained)\n",
    "            index.add(xb)\n",
    "        return DataLoader(self.valid_dataset,sampler, batch_size=self.batch_size, shuffle=False,num_workers=cpu_count())\n",
    "    \n",
    "    @gpu_mem_restore\n",
    "    def test_dataloader(self):\n",
    "        sampler = check_sampler(self.test_dataset)\n",
    "           #FAISS INDEX\n",
    "            #EP para todas as passagens offline\n",
    "            index = faiss.IndexFlatL2(d)   # build the index\n",
    "            print(index.is_trained)\n",
    "            index.add(xb)\n",
    "        return DataLoader(self.test_dataset, sampler,batch_size=self.batch_size,shuffle=False, num_workers=cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjZZhjixzXGN"
   },
   "source": [
    "## Número de parâmetros do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3SGQDjN8w5L"
   },
   "outputs": [],
   "source": [
    "all_data = [ds_train,ds_val,ds_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onnb-4cIZmNt"
   },
   "outputs": [],
   "source": [
    "model = T5Finetuner(hparams, all_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EaXoBX2Qza8I",
    "outputId": "5e863659-230e-4faa-b226-e0316d25fce6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(60506880)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([torch.tensor(x.size()).prod() for x in model.parameters() if x.requires_grad]) # trainable parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDcbeDvO71VL"
   },
   "source": [
    "## Testando rapidamente o modelo em treino, validação e teste com um batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "739af17beb2444c48b76dd9caee0a35c",
      "d3b42130b298455a906c23b594fa4893",
      "343b49f95dd0437ea80102092469017c",
      "499e4cf91ef3419e91f5b38b70f63246",
      "058e6ba13fab4eb29f1b830391b981dd",
      "92911b01ad6f4e618b87ead4444fd840",
      "58115f14ec9948de9bd6f7d277452252",
      "f3ca94ebdd97489e8c36d21f2d0ac83b",
      "25eda07be1d1480d8029f126d2b257a8",
      "5b71736916264afa9af47d64cc78bc61",
      "24a70bdb9f6e4e27b4fddf51d22e91ea",
      "e69b9a611355430880320753f6c79a83",
      "e195b449d0db42468a235afc8bad8913",
      "b2ac3120b5ca420ca65943fe13104b78",
      "2e48c5d32723497db817d029dd731d75",
      "ad90ede6b7384ff2ae467a2e4b35f2b9",
      "75ff9af7225e4a9592ee3282cb3191f4",
      "2c7bc0cbcf3641daad406d35d5cf1146",
      "c191ebf5cf8b4a3485244cb500b5d711",
      "0d926a40b9ad4fbab0219962cc42b10a",
      "685f8fb69ba44132896dda7c856669ce",
      "47299bc0a61f428e944a217e50606eb5",
      "c604ffb933d04f10858a304766950843",
      "59db0d5b0493455b8c97b5226cd09cdd"
     ]
    },
    "colab_type": "code",
    "id": "P2f6OPLGQcBW",
    "outputId": "14d160fc-895c-443f-d2de-65f87e90f6b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:\n",
      "    | Name                                                                  | Type                       | Params\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                                 | T5ForConditionalGeneration | 60 M  \n",
      "1   | model.shared                                                          | Embedding                  | 16 M  \n",
      "2   | model.encoder                                                         | T5Stack                    | 35 M  \n",
      "3   | model.encoder.block                                                   | ModuleList                 | 18 M  \n",
      "4   | model.encoder.block.0                                                 | T5Block                    | 3 M   \n",
      "5   | model.encoder.block.0.layer                                           | ModuleList                 | 3 M   \n",
      "6   | model.encoder.block.0.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "7   | model.encoder.block.0.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "8   | model.encoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "9   | model.encoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "10  | model.encoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "11  | model.encoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 256   \n",
      "13  | model.encoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "14  | model.encoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "15  | model.encoder.block.0.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "16  | model.encoder.block.0.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "17  | model.encoder.block.0.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "18  | model.encoder.block.0.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "20  | model.encoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "21  | model.encoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "22  | model.encoder.block.1                                                 | T5Block                    | 3 M   \n",
      "23  | model.encoder.block.1.layer                                           | ModuleList                 | 3 M   \n",
      "24  | model.encoder.block.1.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "25  | model.encoder.block.1.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "26  | model.encoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "27  | model.encoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "28  | model.encoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "29  | model.encoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "30  | model.encoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "31  | model.encoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "32  | model.encoder.block.1.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "33  | model.encoder.block.1.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "34  | model.encoder.block.1.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "35  | model.encoder.block.1.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "37  | model.encoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "38  | model.encoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "39  | model.encoder.block.2                                                 | T5Block                    | 3 M   \n",
      "40  | model.encoder.block.2.layer                                           | ModuleList                 | 3 M   \n",
      "41  | model.encoder.block.2.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "42  | model.encoder.block.2.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "43  | model.encoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "44  | model.encoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "45  | model.encoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "46  | model.encoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "47  | model.encoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "48  | model.encoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "49  | model.encoder.block.2.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "50  | model.encoder.block.2.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "51  | model.encoder.block.2.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "52  | model.encoder.block.2.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "54  | model.encoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "55  | model.encoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "56  | model.encoder.block.3                                                 | T5Block                    | 3 M   \n",
      "57  | model.encoder.block.3.layer                                           | ModuleList                 | 3 M   \n",
      "58  | model.encoder.block.3.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "59  | model.encoder.block.3.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "60  | model.encoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "61  | model.encoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "62  | model.encoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "63  | model.encoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "64  | model.encoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "65  | model.encoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "66  | model.encoder.block.3.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "67  | model.encoder.block.3.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "68  | model.encoder.block.3.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "69  | model.encoder.block.3.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "71  | model.encoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "72  | model.encoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "73  | model.encoder.block.4                                                 | T5Block                    | 3 M   \n",
      "74  | model.encoder.block.4.layer                                           | ModuleList                 | 3 M   \n",
      "75  | model.encoder.block.4.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "76  | model.encoder.block.4.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "77  | model.encoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "78  | model.encoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "79  | model.encoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "80  | model.encoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "81  | model.encoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "82  | model.encoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "83  | model.encoder.block.4.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "84  | model.encoder.block.4.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "85  | model.encoder.block.4.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "86  | model.encoder.block.4.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "88  | model.encoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "89  | model.encoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "90  | model.encoder.block.5                                                 | T5Block                    | 3 M   \n",
      "91  | model.encoder.block.5.layer                                           | ModuleList                 | 3 M   \n",
      "92  | model.encoder.block.5.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "93  | model.encoder.block.5.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "94  | model.encoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "95  | model.encoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "96  | model.encoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "97  | model.encoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "98  | model.encoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "99  | model.encoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "100 | model.encoder.block.5.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "101 | model.encoder.block.5.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "102 | model.encoder.block.5.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "103 | model.encoder.block.5.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "105 | model.encoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "106 | model.encoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "107 | model.encoder.final_layer_norm                                        | T5LayerNorm                | 512   \n",
      "108 | model.encoder.dropout                                                 | Dropout                    | 0     \n",
      "109 | model.decoder                                                         | T5Stack                    | 41 M  \n",
      "110 | model.decoder.block                                                   | ModuleList                 | 25 M  \n",
      "111 | model.decoder.block.0                                                 | T5Block                    | 4 M   \n",
      "112 | model.decoder.block.0.layer                                           | ModuleList                 | 4 M   \n",
      "113 | model.decoder.block.0.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "114 | model.decoder.block.0.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "115 | model.decoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "116 | model.decoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "117 | model.decoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "118 | model.decoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "119 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 256   \n",
      "120 | model.decoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "121 | model.decoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "122 | model.decoder.block.0.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "123 | model.decoder.block.0.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "124 | model.decoder.block.0.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "125 | model.decoder.block.0.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "126 | model.decoder.block.0.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "127 | model.decoder.block.0.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "128 | model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias | Embedding                  | 256   \n",
      "129 | model.decoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "130 | model.decoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "131 | model.decoder.block.0.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "132 | model.decoder.block.0.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "133 | model.decoder.block.0.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "134 | model.decoder.block.0.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "135 | model.decoder.block.0.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "136 | model.decoder.block.0.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "137 | model.decoder.block.0.layer.2.dropout                                 | Dropout                    | 0     \n",
      "138 | model.decoder.block.1                                                 | T5Block                    | 4 M   \n",
      "139 | model.decoder.block.1.layer                                           | ModuleList                 | 4 M   \n",
      "140 | model.decoder.block.1.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "141 | model.decoder.block.1.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "142 | model.decoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "143 | model.decoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "144 | model.decoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "145 | model.decoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "146 | model.decoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "147 | model.decoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "148 | model.decoder.block.1.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "149 | model.decoder.block.1.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "150 | model.decoder.block.1.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "151 | model.decoder.block.1.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "152 | model.decoder.block.1.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "153 | model.decoder.block.1.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "154 | model.decoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "155 | model.decoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "156 | model.decoder.block.1.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "157 | model.decoder.block.1.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "158 | model.decoder.block.1.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "159 | model.decoder.block.1.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "160 | model.decoder.block.1.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "161 | model.decoder.block.1.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "162 | model.decoder.block.1.layer.2.dropout                                 | Dropout                    | 0     \n",
      "163 | model.decoder.block.2                                                 | T5Block                    | 4 M   \n",
      "164 | model.decoder.block.2.layer                                           | ModuleList                 | 4 M   \n",
      "165 | model.decoder.block.2.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "166 | model.decoder.block.2.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "167 | model.decoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "168 | model.decoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "169 | model.decoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "170 | model.decoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "171 | model.decoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "172 | model.decoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "173 | model.decoder.block.2.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "174 | model.decoder.block.2.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "175 | model.decoder.block.2.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "176 | model.decoder.block.2.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "177 | model.decoder.block.2.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "178 | model.decoder.block.2.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "179 | model.decoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "180 | model.decoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "181 | model.decoder.block.2.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "182 | model.decoder.block.2.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "183 | model.decoder.block.2.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "184 | model.decoder.block.2.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "185 | model.decoder.block.2.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "186 | model.decoder.block.2.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "187 | model.decoder.block.2.layer.2.dropout                                 | Dropout                    | 0     \n",
      "188 | model.decoder.block.3                                                 | T5Block                    | 4 M   \n",
      "189 | model.decoder.block.3.layer                                           | ModuleList                 | 4 M   \n",
      "190 | model.decoder.block.3.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "191 | model.decoder.block.3.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "192 | model.decoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "193 | model.decoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "194 | model.decoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "195 | model.decoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "196 | model.decoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "197 | model.decoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "198 | model.decoder.block.3.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "199 | model.decoder.block.3.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "200 | model.decoder.block.3.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "201 | model.decoder.block.3.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "202 | model.decoder.block.3.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "203 | model.decoder.block.3.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "204 | model.decoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "205 | model.decoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "206 | model.decoder.block.3.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "207 | model.decoder.block.3.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "208 | model.decoder.block.3.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "209 | model.decoder.block.3.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "210 | model.decoder.block.3.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "211 | model.decoder.block.3.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "212 | model.decoder.block.3.layer.2.dropout                                 | Dropout                    | 0     \n",
      "213 | model.decoder.block.4                                                 | T5Block                    | 4 M   \n",
      "214 | model.decoder.block.4.layer                                           | ModuleList                 | 4 M   \n",
      "215 | model.decoder.block.4.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "216 | model.decoder.block.4.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "217 | model.decoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "218 | model.decoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "219 | model.decoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "220 | model.decoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "221 | model.decoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "222 | model.decoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "223 | model.decoder.block.4.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "224 | model.decoder.block.4.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "225 | model.decoder.block.4.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "226 | model.decoder.block.4.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "227 | model.decoder.block.4.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "228 | model.decoder.block.4.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "229 | model.decoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "230 | model.decoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "231 | model.decoder.block.4.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "232 | model.decoder.block.4.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "233 | model.decoder.block.4.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "234 | model.decoder.block.4.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "235 | model.decoder.block.4.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "236 | model.decoder.block.4.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "237 | model.decoder.block.4.layer.2.dropout                                 | Dropout                    | 0     \n",
      "238 | model.decoder.block.5                                                 | T5Block                    | 4 M   \n",
      "239 | model.decoder.block.5.layer                                           | ModuleList                 | 4 M   \n",
      "240 | model.decoder.block.5.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "241 | model.decoder.block.5.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "242 | model.decoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "243 | model.decoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "244 | model.decoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "245 | model.decoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "246 | model.decoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "247 | model.decoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "248 | model.decoder.block.5.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "249 | model.decoder.block.5.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "250 | model.decoder.block.5.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "251 | model.decoder.block.5.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "252 | model.decoder.block.5.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "253 | model.decoder.block.5.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "254 | model.decoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "255 | model.decoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "256 | model.decoder.block.5.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "257 | model.decoder.block.5.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "258 | model.decoder.block.5.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "259 | model.decoder.block.5.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "260 | model.decoder.block.5.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "261 | model.decoder.block.5.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "262 | model.decoder.block.5.layer.2.dropout                                 | Dropout                    | 0     \n",
      "263 | model.decoder.final_layer_norm                                        | T5LayerNorm                | 512   \n",
      "264 | model.decoder.dropout                                                 | Dropout                    | 0     \n",
      "265 | model.lm_head                                                         | Linear                     | 16 M  \n",
      "266 | loss_funtion                                                          | CrossEntropyLoss           | 0     \n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739af17beb2444c48b76dd9caee0a35c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25eda07be1d1480d8029f126d2b257a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ff9af7225e4a9592ee3282cb3191f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'avg_test_bleu': 0.0}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, \n",
    "                     checkpoint_callback=False,  # Disable checkpoint saving.\n",
    "                     fast_dev_run=True)\n",
    "trainer.fit(model)\n",
    "trainer.test(model)\n",
    "# Para não ter estouro de mémoria da GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvySFkn66R_u"
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kS2bjddQu87g"
   },
   "source": [
    "## Overfit em algumas amostras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BEr29GIhBNKs"
   },
   "source": [
    "Antes de treinar o modelo no dataset todo, faremos overfit do \n",
    "modelo em poucas de treino para verificar se loss vai para próximo de 0. Isso serve para depurar se a implementação do modelo está correta.\n",
    "\n",
    "Podemos também medir se a acurácia neste minibatch chega perto de 100%. Isso serve para depurar se nossa função que mede a acurácia está correta.\n",
    "\n",
    "Nota: se treinarmos por muitas épocas (ex: 500) é possivel que a loss vá para zero mesmo com bugs na implementação. O ideal é que a loss chege próxima a zero antes de 100 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1529dba528b542ce9960eda75d46ad96",
      "d22ccd5f2b4d45b0b8b5619040d59b57",
      "ab0448670ef84ef38b63ab986f3b0bb9",
      "4cc15c30f78b42caa7c1b40d5e687450",
      "614ddfd9f7d748829143cde3cf43f043",
      "c3854aee523542298f2586e298e563d1",
      "d040f2d40b0b4b9bac795e0c108dcb04",
      "9a0eed9192a5440880ae2554a4bc41f6",
      "02eeb3f2accf42a9a7581215cf8c3933",
      "6c765ad902a046b7b3d0b3440ccccf12",
      "7a2fb72523a94eba986ae0b8441a21c6",
      "6416cc0a86a742ec85a6aac205a5b480",
      "f5852d39a93e470cbca4482b524e5feb",
      "63552451ca7a431b8f35e3943f2079ad",
      "968ab69b521c4b09b4448c5cda99a9e9",
      "c116be289b384886a95de435d8a9d6ea",
      "d473c55ed0a84501908ce502601b3da5",
      "77b9502293e54a059640adebc044aaf6",
      "80d361cd69ca4d7aa4b313c0e824e66d",
      "3efb59b711cd4c98bb8afb62988d57b8",
      "0d41d0a6e38d4593943ff061807e40d1",
      "1be21389a0674fc994ee3f954b052c89",
      "9d715f95de4048e5943c23f2fd67fd47",
      "e6913d040ed54329acf907275010feb7",
      "7d615c8423174f3b8bcb9870936adf2d",
      "df6114e28226459199e5b54cd36fbb5c",
      "00cface36bcb4a5c8450b9dc0457d5f4",
      "59df790c53f94047b49f5a08b4eaff4d",
      "a21300fb32254fae914de74371e82951",
      "8cc48d01a43b4d5280ac8966375ec6cf",
      "6935e20239f0436db3fd3f94a697df35",
      "d150607ab5ac48f380d8e0ddba0d0c5c",
      "0ed175e00fb040199221454484c2ce36",
      "1853255b8dbb43c9a1b6586c8ded37eb",
      "7c5c33a4a56a4635aeb34ad58fac28ad",
      "fb69c3051eed413095b8b37dfa9f709a",
      "3386da8ca76c40e7814ae179bfc86319",
      "4dcd98df7ce349af8d8aa7e77c9e9ca0",
      "b6ad1cf50b6d4ffd867f51a0fe177668",
      "5b1a47e76ee744caba0555b7ef0f95b8"
     ]
    },
    "colab_type": "code",
    "id": "92RcHIEONdzB",
    "outputId": "dd0e74ae-9929-4192-9c32-856f8b7103eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:\n",
      "    | Name                                                                  | Type                       | Params\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                                 | T5ForConditionalGeneration | 60 M  \n",
      "1   | model.shared                                                          | Embedding                  | 16 M  \n",
      "2   | model.encoder                                                         | T5Stack                    | 35 M  \n",
      "3   | model.encoder.block                                                   | ModuleList                 | 18 M  \n",
      "4   | model.encoder.block.0                                                 | T5Block                    | 3 M   \n",
      "5   | model.encoder.block.0.layer                                           | ModuleList                 | 3 M   \n",
      "6   | model.encoder.block.0.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "7   | model.encoder.block.0.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "8   | model.encoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "9   | model.encoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "10  | model.encoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "11  | model.encoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 256   \n",
      "13  | model.encoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "14  | model.encoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "15  | model.encoder.block.0.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "16  | model.encoder.block.0.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "17  | model.encoder.block.0.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "18  | model.encoder.block.0.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "20  | model.encoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "21  | model.encoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "22  | model.encoder.block.1                                                 | T5Block                    | 3 M   \n",
      "23  | model.encoder.block.1.layer                                           | ModuleList                 | 3 M   \n",
      "24  | model.encoder.block.1.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "25  | model.encoder.block.1.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "26  | model.encoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "27  | model.encoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "28  | model.encoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "29  | model.encoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "30  | model.encoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "31  | model.encoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "32  | model.encoder.block.1.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "33  | model.encoder.block.1.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "34  | model.encoder.block.1.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "35  | model.encoder.block.1.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "37  | model.encoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "38  | model.encoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "39  | model.encoder.block.2                                                 | T5Block                    | 3 M   \n",
      "40  | model.encoder.block.2.layer                                           | ModuleList                 | 3 M   \n",
      "41  | model.encoder.block.2.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "42  | model.encoder.block.2.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "43  | model.encoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "44  | model.encoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "45  | model.encoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "46  | model.encoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "47  | model.encoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "48  | model.encoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "49  | model.encoder.block.2.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "50  | model.encoder.block.2.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "51  | model.encoder.block.2.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "52  | model.encoder.block.2.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "54  | model.encoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "55  | model.encoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "56  | model.encoder.block.3                                                 | T5Block                    | 3 M   \n",
      "57  | model.encoder.block.3.layer                                           | ModuleList                 | 3 M   \n",
      "58  | model.encoder.block.3.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "59  | model.encoder.block.3.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "60  | model.encoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "61  | model.encoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "62  | model.encoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "63  | model.encoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "64  | model.encoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "65  | model.encoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "66  | model.encoder.block.3.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "67  | model.encoder.block.3.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "68  | model.encoder.block.3.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "69  | model.encoder.block.3.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "71  | model.encoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "72  | model.encoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "73  | model.encoder.block.4                                                 | T5Block                    | 3 M   \n",
      "74  | model.encoder.block.4.layer                                           | ModuleList                 | 3 M   \n",
      "75  | model.encoder.block.4.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "76  | model.encoder.block.4.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "77  | model.encoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "78  | model.encoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "79  | model.encoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "80  | model.encoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "81  | model.encoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "82  | model.encoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "83  | model.encoder.block.4.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "84  | model.encoder.block.4.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "85  | model.encoder.block.4.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "86  | model.encoder.block.4.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "88  | model.encoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "89  | model.encoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "90  | model.encoder.block.5                                                 | T5Block                    | 3 M   \n",
      "91  | model.encoder.block.5.layer                                           | ModuleList                 | 3 M   \n",
      "92  | model.encoder.block.5.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "93  | model.encoder.block.5.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "94  | model.encoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "95  | model.encoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "96  | model.encoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "97  | model.encoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "98  | model.encoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "99  | model.encoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "100 | model.encoder.block.5.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "101 | model.encoder.block.5.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "102 | model.encoder.block.5.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "103 | model.encoder.block.5.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "105 | model.encoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "106 | model.encoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "107 | model.encoder.final_layer_norm                                        | T5LayerNorm                | 512   \n",
      "108 | model.encoder.dropout                                                 | Dropout                    | 0     \n",
      "109 | model.decoder                                                         | T5Stack                    | 41 M  \n",
      "110 | model.decoder.block                                                   | ModuleList                 | 25 M  \n",
      "111 | model.decoder.block.0                                                 | T5Block                    | 4 M   \n",
      "112 | model.decoder.block.0.layer                                           | ModuleList                 | 4 M   \n",
      "113 | model.decoder.block.0.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "114 | model.decoder.block.0.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "115 | model.decoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "116 | model.decoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "117 | model.decoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "118 | model.decoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "119 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 256   \n",
      "120 | model.decoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "121 | model.decoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "122 | model.decoder.block.0.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "123 | model.decoder.block.0.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "124 | model.decoder.block.0.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "125 | model.decoder.block.0.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "126 | model.decoder.block.0.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "127 | model.decoder.block.0.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "128 | model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias | Embedding                  | 256   \n",
      "129 | model.decoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "130 | model.decoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "131 | model.decoder.block.0.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "132 | model.decoder.block.0.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "133 | model.decoder.block.0.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "134 | model.decoder.block.0.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "135 | model.decoder.block.0.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "136 | model.decoder.block.0.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "137 | model.decoder.block.0.layer.2.dropout                                 | Dropout                    | 0     \n",
      "138 | model.decoder.block.1                                                 | T5Block                    | 4 M   \n",
      "139 | model.decoder.block.1.layer                                           | ModuleList                 | 4 M   \n",
      "140 | model.decoder.block.1.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "141 | model.decoder.block.1.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "142 | model.decoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "143 | model.decoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "144 | model.decoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "145 | model.decoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "146 | model.decoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "147 | model.decoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "148 | model.decoder.block.1.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "149 | model.decoder.block.1.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "150 | model.decoder.block.1.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "151 | model.decoder.block.1.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "152 | model.decoder.block.1.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "153 | model.decoder.block.1.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "154 | model.decoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "155 | model.decoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "156 | model.decoder.block.1.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "157 | model.decoder.block.1.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "158 | model.decoder.block.1.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "159 | model.decoder.block.1.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "160 | model.decoder.block.1.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "161 | model.decoder.block.1.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "162 | model.decoder.block.1.layer.2.dropout                                 | Dropout                    | 0     \n",
      "163 | model.decoder.block.2                                                 | T5Block                    | 4 M   \n",
      "164 | model.decoder.block.2.layer                                           | ModuleList                 | 4 M   \n",
      "165 | model.decoder.block.2.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "166 | model.decoder.block.2.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "167 | model.decoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "168 | model.decoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "169 | model.decoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "170 | model.decoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "171 | model.decoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "172 | model.decoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "173 | model.decoder.block.2.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "174 | model.decoder.block.2.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "175 | model.decoder.block.2.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "176 | model.decoder.block.2.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "177 | model.decoder.block.2.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "178 | model.decoder.block.2.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "179 | model.decoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "180 | model.decoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "181 | model.decoder.block.2.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "182 | model.decoder.block.2.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "183 | model.decoder.block.2.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "184 | model.decoder.block.2.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "185 | model.decoder.block.2.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "186 | model.decoder.block.2.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "187 | model.decoder.block.2.layer.2.dropout                                 | Dropout                    | 0     \n",
      "188 | model.decoder.block.3                                                 | T5Block                    | 4 M   \n",
      "189 | model.decoder.block.3.layer                                           | ModuleList                 | 4 M   \n",
      "190 | model.decoder.block.3.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "191 | model.decoder.block.3.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "192 | model.decoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "193 | model.decoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "194 | model.decoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "195 | model.decoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "196 | model.decoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "197 | model.decoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "198 | model.decoder.block.3.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "199 | model.decoder.block.3.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "200 | model.decoder.block.3.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "201 | model.decoder.block.3.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "202 | model.decoder.block.3.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "203 | model.decoder.block.3.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "204 | model.decoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "205 | model.decoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "206 | model.decoder.block.3.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "207 | model.decoder.block.3.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "208 | model.decoder.block.3.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "209 | model.decoder.block.3.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "210 | model.decoder.block.3.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "211 | model.decoder.block.3.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "212 | model.decoder.block.3.layer.2.dropout                                 | Dropout                    | 0     \n",
      "213 | model.decoder.block.4                                                 | T5Block                    | 4 M   \n",
      "214 | model.decoder.block.4.layer                                           | ModuleList                 | 4 M   \n",
      "215 | model.decoder.block.4.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "216 | model.decoder.block.4.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "217 | model.decoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "218 | model.decoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "219 | model.decoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "220 | model.decoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "221 | model.decoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "222 | model.decoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "223 | model.decoder.block.4.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "224 | model.decoder.block.4.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "225 | model.decoder.block.4.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "226 | model.decoder.block.4.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "227 | model.decoder.block.4.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "228 | model.decoder.block.4.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "229 | model.decoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "230 | model.decoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "231 | model.decoder.block.4.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "232 | model.decoder.block.4.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "233 | model.decoder.block.4.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "234 | model.decoder.block.4.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "235 | model.decoder.block.4.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "236 | model.decoder.block.4.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "237 | model.decoder.block.4.layer.2.dropout                                 | Dropout                    | 0     \n",
      "238 | model.decoder.block.5                                                 | T5Block                    | 4 M   \n",
      "239 | model.decoder.block.5.layer                                           | ModuleList                 | 4 M   \n",
      "240 | model.decoder.block.5.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "241 | model.decoder.block.5.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "242 | model.decoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "243 | model.decoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "244 | model.decoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "245 | model.decoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "246 | model.decoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "247 | model.decoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "248 | model.decoder.block.5.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "249 | model.decoder.block.5.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "250 | model.decoder.block.5.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "251 | model.decoder.block.5.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "252 | model.decoder.block.5.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "253 | model.decoder.block.5.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "254 | model.decoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "255 | model.decoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "256 | model.decoder.block.5.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "257 | model.decoder.block.5.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "258 | model.decoder.block.5.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "259 | model.decoder.block.5.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "260 | model.decoder.block.5.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "261 | model.decoder.block.5.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "262 | model.decoder.block.5.layer.2.dropout                                 | Dropout                    | 0     \n",
      "263 | model.decoder.final_layer_norm                                        | T5LayerNorm                | 512   \n",
      "264 | model.decoder.dropout                                                 | Dropout                    | 0     \n",
      "265 | model.lm_head                                                         | Linear                     | 16 M  \n",
      "266 | loss_funtion                                                          | CrossEntropyLoss           | 0     \n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1529dba528b542ce9960eda75d46ad96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02eeb3f2accf42a9a7581215cf8c3933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d473c55ed0a84501908ce502601b3da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d615c8423174f3b8bcb9870936adf2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed175e00fb040199221454484c2ce36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action              \t|  Mean duration (s)\t|  Total time (s) \n",
      "-----------------------------------------------------------------\n",
      "on_train_start      \t|  0.027183       \t|  0.027183       \n",
      "on_epoch_start      \t|  0.0028499      \t|  0.085497       \n",
      "get_train_batch     \t|  0.0073753      \t|  13.939         \n",
      "on_batch_start      \t|  2.3386e-05     \t|  0.043499       \n",
      "model_forward       \t|  0.043691       \t|  81.265         \n",
      "model_backward      \t|  0.14442        \t|  268.62         \n",
      "on_after_backward   \t|  3.3294e-06     \t|  0.0061927      \n",
      "on_batch_end        \t|  0.0032431      \t|  6.0321         \n",
      "optimizer_step      \t|  0.017758       \t|  16.515         \n",
      "on_epoch_end        \t|  1.7534e-05     \t|  0.00052601     \n",
      "on_train_end        \t|  0.001308       \t|  0.001308       \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1,\n",
    "                     max_epochs=30,\n",
    "                     check_val_every_n_epoch=10,\n",
    "                     checkpoint_callback=False,  # Disable checkpoint saving\n",
    "                     overfit_pct=0.005,\n",
    "                     profiler=True,\n",
    "                     accumulate_grad_batches=accumulate_grad_batches)\n",
    "all_data = [ds_train]\n",
    "model = T5Finetuner(hparams, all_data,overfit=True )\n",
    "trainer.fit(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193,
     "referenced_widgets": [
      "1a56ca60f6d941869c470d70b650655b",
      "afdf8049dcdc44fb88eddcb142a0e96b",
      "43455503fbcb40989b553a992881f6e3",
      "a6de18ac16d64e7192318f493cfb7706",
      "2c2860c52b794dd381bf935b9004bee9",
      "fd97557e76874f06a0a01213cea95032",
      "00af6e41422d4d138cbd5c67038339ae",
      "907d4431dc634e9da33db98818711ac7"
     ]
    },
    "colab_type": "code",
    "id": "iCSfrdIr-vf-",
    "outputId": "af2322f3-64b0-4fe3-89fb-206903b20ddb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a56ca60f6d941869c470d70b650655b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'avg_test_bleu': 64.05501862497174}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xKyUgo7u89XH"
   },
   "outputs": [],
   "source": [
    "del model  # Para não ter estouro de mémoria da GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKEddD8nvSpt"
   },
   "source": [
    "## Treinamento e Validação no dataset todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhCyJXqwu2xB"
   },
   "source": [
    "Salvamento parcial (Israel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QQgoG6OGu13r",
    "outputId": "927a89cd-f176-4846-e220-0f94d3bfbc9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_steps = len(ds_train) # how many training steps will happen\n",
    "save_times = 1000\n",
    "save_every = n_steps // save_times\n",
    "save_every"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0b4df8d14cbf482292a02aa81e8d2f66",
      "535354ff470242bf8aaaf087c27806b1",
      "cfee76d204384008bd36a42bff7c0e0d",
      "50911aecd9274e8295903bbe488174b1",
      "79bff1036b1b4a77b8f94af6f9b24e8a",
      "ed2194a6a9b34d24977087ff9cb281e9",
      "925f96aad8234eb7864a5a4c351120f9",
      "ebf3bcdbf9b34df4b56e519fdf423606",
      "3b9e2640ff584b9aa479ffcb9e4537f2",
      "270e6f274e31485fadc0f901a5f9586c",
      "ec8f393dfde44798a9ea2fdbb0e32c36",
      "1d3322cb394d41d6b5e6cf3b77777732",
      "f4226b9f12394b8a8b32c8dd6a3ea5dc",
      "7afbb4c50a21436085a25f49bac80c88",
      "919c55aa170d4d9a9a46732f355009df",
      "637927947f1d4821ba6773d02c5e5c77"
     ]
    },
    "colab_type": "code",
    "id": "V9RzCYcavfhR",
    "outputId": "98f23f38-3c5a-4f92-a80b-a6f4520a7167"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in /content/drive/My Drive/Mestrado/PLN/Solucoes_Entregues/checkpoint_save/lab9/checkpoints_epocas: ['epoch=0.ckpt']\n",
      "Saving checkpoints to /content/drive/My Drive/Mestrado/PLN/Solucoes_Entregues/checkpoint_save/lab9/checkpoints_epocas\n",
      "Restoring checkpoint: /content/drive/My Drive/Mestrado/PLN/Solucoes_Entregues/checkpoint_save/lab9/checkpoints_epocas/epoch=0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "    | Name                                                                  | Type                       | Params\n",
      "-----------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                                 | T5ForConditionalGeneration | 60 M  \n",
      "1   | model.shared                                                          | Embedding                  | 16 M  \n",
      "2   | model.encoder                                                         | T5Stack                    | 35 M  \n",
      "3   | model.encoder.block                                                   | ModuleList                 | 18 M  \n",
      "4   | model.encoder.block.0                                                 | T5Block                    | 3 M   \n",
      "5   | model.encoder.block.0.layer                                           | ModuleList                 | 3 M   \n",
      "6   | model.encoder.block.0.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "7   | model.encoder.block.0.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "8   | model.encoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "9   | model.encoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "10  | model.encoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "11  | model.encoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "12  | model.encoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 256   \n",
      "13  | model.encoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "14  | model.encoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "15  | model.encoder.block.0.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "16  | model.encoder.block.0.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "17  | model.encoder.block.0.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "18  | model.encoder.block.0.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "19  | model.encoder.block.0.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "20  | model.encoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "21  | model.encoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "22  | model.encoder.block.1                                                 | T5Block                    | 3 M   \n",
      "23  | model.encoder.block.1.layer                                           | ModuleList                 | 3 M   \n",
      "24  | model.encoder.block.1.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "25  | model.encoder.block.1.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "26  | model.encoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "27  | model.encoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "28  | model.encoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "29  | model.encoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "30  | model.encoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "31  | model.encoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "32  | model.encoder.block.1.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "33  | model.encoder.block.1.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "34  | model.encoder.block.1.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "35  | model.encoder.block.1.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "36  | model.encoder.block.1.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "37  | model.encoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "38  | model.encoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "39  | model.encoder.block.2                                                 | T5Block                    | 3 M   \n",
      "40  | model.encoder.block.2.layer                                           | ModuleList                 | 3 M   \n",
      "41  | model.encoder.block.2.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "42  | model.encoder.block.2.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "43  | model.encoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "44  | model.encoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "45  | model.encoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "46  | model.encoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "47  | model.encoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "48  | model.encoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "49  | model.encoder.block.2.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "50  | model.encoder.block.2.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "51  | model.encoder.block.2.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "52  | model.encoder.block.2.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "53  | model.encoder.block.2.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "54  | model.encoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "55  | model.encoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "56  | model.encoder.block.3                                                 | T5Block                    | 3 M   \n",
      "57  | model.encoder.block.3.layer                                           | ModuleList                 | 3 M   \n",
      "58  | model.encoder.block.3.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "59  | model.encoder.block.3.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "60  | model.encoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "61  | model.encoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "62  | model.encoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "63  | model.encoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "64  | model.encoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "65  | model.encoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "66  | model.encoder.block.3.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "67  | model.encoder.block.3.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "68  | model.encoder.block.3.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "69  | model.encoder.block.3.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "70  | model.encoder.block.3.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "71  | model.encoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "72  | model.encoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "73  | model.encoder.block.4                                                 | T5Block                    | 3 M   \n",
      "74  | model.encoder.block.4.layer                                           | ModuleList                 | 3 M   \n",
      "75  | model.encoder.block.4.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "76  | model.encoder.block.4.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "77  | model.encoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "78  | model.encoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "79  | model.encoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "80  | model.encoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "81  | model.encoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "82  | model.encoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "83  | model.encoder.block.4.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "84  | model.encoder.block.4.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "85  | model.encoder.block.4.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "86  | model.encoder.block.4.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "87  | model.encoder.block.4.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "88  | model.encoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "89  | model.encoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "90  | model.encoder.block.5                                                 | T5Block                    | 3 M   \n",
      "91  | model.encoder.block.5.layer                                           | ModuleList                 | 3 M   \n",
      "92  | model.encoder.block.5.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "93  | model.encoder.block.5.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "94  | model.encoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "95  | model.encoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "96  | model.encoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "97  | model.encoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "98  | model.encoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "99  | model.encoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "100 | model.encoder.block.5.layer.1                                         | T5LayerFF                  | 2 M   \n",
      "101 | model.encoder.block.5.layer.1.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "102 | model.encoder.block.5.layer.1.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "103 | model.encoder.block.5.layer.1.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "104 | model.encoder.block.5.layer.1.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "105 | model.encoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "106 | model.encoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "107 | model.encoder.final_layer_norm                                        | T5LayerNorm                | 512   \n",
      "108 | model.encoder.dropout                                                 | Dropout                    | 0     \n",
      "109 | model.decoder                                                         | T5Stack                    | 41 M  \n",
      "110 | model.decoder.block                                                   | ModuleList                 | 25 M  \n",
      "111 | model.decoder.block.0                                                 | T5Block                    | 4 M   \n",
      "112 | model.decoder.block.0.layer                                           | ModuleList                 | 4 M   \n",
      "113 | model.decoder.block.0.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "114 | model.decoder.block.0.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "115 | model.decoder.block.0.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "116 | model.decoder.block.0.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "117 | model.decoder.block.0.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "118 | model.decoder.block.0.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "119 | model.decoder.block.0.layer.0.SelfAttention.relative_attention_bias   | Embedding                  | 256   \n",
      "120 | model.decoder.block.0.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "121 | model.decoder.block.0.layer.0.dropout                                 | Dropout                    | 0     \n",
      "122 | model.decoder.block.0.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "123 | model.decoder.block.0.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "124 | model.decoder.block.0.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "125 | model.decoder.block.0.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "126 | model.decoder.block.0.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "127 | model.decoder.block.0.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "128 | model.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias | Embedding                  | 256   \n",
      "129 | model.decoder.block.0.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "130 | model.decoder.block.0.layer.1.dropout                                 | Dropout                    | 0     \n",
      "131 | model.decoder.block.0.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "132 | model.decoder.block.0.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "133 | model.decoder.block.0.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "134 | model.decoder.block.0.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "135 | model.decoder.block.0.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "136 | model.decoder.block.0.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "137 | model.decoder.block.0.layer.2.dropout                                 | Dropout                    | 0     \n",
      "138 | model.decoder.block.1                                                 | T5Block                    | 4 M   \n",
      "139 | model.decoder.block.1.layer                                           | ModuleList                 | 4 M   \n",
      "140 | model.decoder.block.1.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "141 | model.decoder.block.1.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "142 | model.decoder.block.1.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "143 | model.decoder.block.1.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "144 | model.decoder.block.1.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "145 | model.decoder.block.1.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "146 | model.decoder.block.1.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "147 | model.decoder.block.1.layer.0.dropout                                 | Dropout                    | 0     \n",
      "148 | model.decoder.block.1.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "149 | model.decoder.block.1.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "150 | model.decoder.block.1.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "151 | model.decoder.block.1.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "152 | model.decoder.block.1.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "153 | model.decoder.block.1.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "154 | model.decoder.block.1.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "155 | model.decoder.block.1.layer.1.dropout                                 | Dropout                    | 0     \n",
      "156 | model.decoder.block.1.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "157 | model.decoder.block.1.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "158 | model.decoder.block.1.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "159 | model.decoder.block.1.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "160 | model.decoder.block.1.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "161 | model.decoder.block.1.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "162 | model.decoder.block.1.layer.2.dropout                                 | Dropout                    | 0     \n",
      "163 | model.decoder.block.2                                                 | T5Block                    | 4 M   \n",
      "164 | model.decoder.block.2.layer                                           | ModuleList                 | 4 M   \n",
      "165 | model.decoder.block.2.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "166 | model.decoder.block.2.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "167 | model.decoder.block.2.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "168 | model.decoder.block.2.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "169 | model.decoder.block.2.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "170 | model.decoder.block.2.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "171 | model.decoder.block.2.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "172 | model.decoder.block.2.layer.0.dropout                                 | Dropout                    | 0     \n",
      "173 | model.decoder.block.2.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "174 | model.decoder.block.2.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "175 | model.decoder.block.2.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "176 | model.decoder.block.2.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "177 | model.decoder.block.2.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "178 | model.decoder.block.2.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "179 | model.decoder.block.2.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "180 | model.decoder.block.2.layer.1.dropout                                 | Dropout                    | 0     \n",
      "181 | model.decoder.block.2.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "182 | model.decoder.block.2.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "183 | model.decoder.block.2.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "184 | model.decoder.block.2.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "185 | model.decoder.block.2.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "186 | model.decoder.block.2.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "187 | model.decoder.block.2.layer.2.dropout                                 | Dropout                    | 0     \n",
      "188 | model.decoder.block.3                                                 | T5Block                    | 4 M   \n",
      "189 | model.decoder.block.3.layer                                           | ModuleList                 | 4 M   \n",
      "190 | model.decoder.block.3.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "191 | model.decoder.block.3.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "192 | model.decoder.block.3.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "193 | model.decoder.block.3.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "194 | model.decoder.block.3.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "195 | model.decoder.block.3.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "196 | model.decoder.block.3.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "197 | model.decoder.block.3.layer.0.dropout                                 | Dropout                    | 0     \n",
      "198 | model.decoder.block.3.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "199 | model.decoder.block.3.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "200 | model.decoder.block.3.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "201 | model.decoder.block.3.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "202 | model.decoder.block.3.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "203 | model.decoder.block.3.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "204 | model.decoder.block.3.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "205 | model.decoder.block.3.layer.1.dropout                                 | Dropout                    | 0     \n",
      "206 | model.decoder.block.3.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "207 | model.decoder.block.3.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "208 | model.decoder.block.3.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "209 | model.decoder.block.3.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "210 | model.decoder.block.3.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "211 | model.decoder.block.3.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "212 | model.decoder.block.3.layer.2.dropout                                 | Dropout                    | 0     \n",
      "213 | model.decoder.block.4                                                 | T5Block                    | 4 M   \n",
      "214 | model.decoder.block.4.layer                                           | ModuleList                 | 4 M   \n",
      "215 | model.decoder.block.4.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "216 | model.decoder.block.4.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "217 | model.decoder.block.4.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "218 | model.decoder.block.4.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "219 | model.decoder.block.4.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "220 | model.decoder.block.4.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "221 | model.decoder.block.4.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "222 | model.decoder.block.4.layer.0.dropout                                 | Dropout                    | 0     \n",
      "223 | model.decoder.block.4.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "224 | model.decoder.block.4.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "225 | model.decoder.block.4.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "226 | model.decoder.block.4.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "227 | model.decoder.block.4.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "228 | model.decoder.block.4.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "229 | model.decoder.block.4.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "230 | model.decoder.block.4.layer.1.dropout                                 | Dropout                    | 0     \n",
      "231 | model.decoder.block.4.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "232 | model.decoder.block.4.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "233 | model.decoder.block.4.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "234 | model.decoder.block.4.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "235 | model.decoder.block.4.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "236 | model.decoder.block.4.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "237 | model.decoder.block.4.layer.2.dropout                                 | Dropout                    | 0     \n",
      "238 | model.decoder.block.5                                                 | T5Block                    | 4 M   \n",
      "239 | model.decoder.block.5.layer                                           | ModuleList                 | 4 M   \n",
      "240 | model.decoder.block.5.layer.0                                         | T5LayerSelfAttention       | 1 M   \n",
      "241 | model.decoder.block.5.layer.0.SelfAttention                           | T5Attention                | 1 M   \n",
      "242 | model.decoder.block.5.layer.0.SelfAttention.q                         | Linear                     | 262 K \n",
      "243 | model.decoder.block.5.layer.0.SelfAttention.k                         | Linear                     | 262 K \n",
      "244 | model.decoder.block.5.layer.0.SelfAttention.v                         | Linear                     | 262 K \n",
      "245 | model.decoder.block.5.layer.0.SelfAttention.o                         | Linear                     | 262 K \n",
      "246 | model.decoder.block.5.layer.0.layer_norm                              | T5LayerNorm                | 512   \n",
      "247 | model.decoder.block.5.layer.0.dropout                                 | Dropout                    | 0     \n",
      "248 | model.decoder.block.5.layer.1                                         | T5LayerCrossAttention      | 1 M   \n",
      "249 | model.decoder.block.5.layer.1.EncDecAttention                         | T5Attention                | 1 M   \n",
      "250 | model.decoder.block.5.layer.1.EncDecAttention.q                       | Linear                     | 262 K \n",
      "251 | model.decoder.block.5.layer.1.EncDecAttention.k                       | Linear                     | 262 K \n",
      "252 | model.decoder.block.5.layer.1.EncDecAttention.v                       | Linear                     | 262 K \n",
      "253 | model.decoder.block.5.layer.1.EncDecAttention.o                       | Linear                     | 262 K \n",
      "254 | model.decoder.block.5.layer.1.layer_norm                              | T5LayerNorm                | 512   \n",
      "255 | model.decoder.block.5.layer.1.dropout                                 | Dropout                    | 0     \n",
      "256 | model.decoder.block.5.layer.2                                         | T5LayerFF                  | 2 M   \n",
      "257 | model.decoder.block.5.layer.2.DenseReluDense                          | T5DenseReluDense           | 2 M   \n",
      "258 | model.decoder.block.5.layer.2.DenseReluDense.wi                       | Linear                     | 1 M   \n",
      "259 | model.decoder.block.5.layer.2.DenseReluDense.wo                       | Linear                     | 1 M   \n",
      "260 | model.decoder.block.5.layer.2.DenseReluDense.dropout                  | Dropout                    | 0     \n",
      "261 | model.decoder.block.5.layer.2.layer_norm                              | T5LayerNorm                | 512   \n",
      "262 | model.decoder.block.5.layer.2.dropout                                 | Dropout                    | 0     \n",
      "263 | model.decoder.final_layer_norm                                        | T5LayerNorm                | 512   \n",
      "264 | model.decoder.dropout                                                 | Dropout                    | 0     \n",
      "265 | model.lm_head                                                         | Linear                     | 16 M  \n",
      "266 | loss_funtion                                                          | CrossEntropyLoss           | 0     \n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4df8d14cbf482292a02aa81e8d2f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9e2640ff584b9aa479ffcb9e4537f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action              \t|  Mean duration (s)\t|  Total time (s) \n",
      "-----------------------------------------------------------------\n",
      "on_train_start      \t|  0.033313       \t|  0.033313       \n",
      "on_train_end        \t|  0.001498       \t|  0.001498       \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_epochs = 1\n",
    "\n",
    "checkpoint_path = '/content/drive/My Drive/Mestrado/PLN/Solucoes_Entregues/checkpoint_save/lab9/checkpoints_epocas/epoch=0.ckpt'\n",
    "checkpoint_dir = os.path.dirname(os.path.abspath(checkpoint_path))\n",
    "print(f'Files in {checkpoint_dir}: {os.listdir(checkpoint_dir)}')\n",
    "print(f'Saving checkpoints to {checkpoint_dir}')\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_dir,\n",
    "                                      save_top_k=-1,\n",
    "                                      monitor=\"val_acc\",\n",
    "                                      mode=\"max\")  # Keeps all checkpoints.\n",
    "\n",
    "\n",
    "resume_from_checkpoint = None\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f'Restoring checkpoint: {checkpoint_path}')\n",
    "    resume_from_checkpoint = checkpoint_path\n",
    "\n",
    "all_data = [ds_train,ds_val,ds_test]\n",
    "trainer = pl.Trainer(gpus=1,\n",
    "                     max_epochs=max_epochs,\n",
    "                     check_val_every_n_epoch=1,\n",
    "                     profiler=True,\n",
    "                     accumulate_grad_batches=accumulate_grad_batches,\n",
    "                     checkpoint_callback=checkpoint_callback,\n",
    "                     progress_bar_refresh_rate=30,\n",
    "                     resume_from_checkpoint=resume_from_checkpoint)\n",
    "\n",
    "model = T5Finetuner(hparams,\n",
    "                    all_data,\n",
    "                    save_every=save_every,\n",
    "                    save_to='/content/drive/My Drive/Mestrado/PLN/Solucoes_Entregues/checkpoint_save/lab9/checkpoints_parciais')\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjN_-W4WZ67q"
   },
   "source": [
    "## Após treinado, avaliamos o modelo no dataset de teste\n",
    "\n",
    "É importante que essa avaliação seja feita poucas vezes para evitar \"overfit manual\" no dataset de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193,
     "referenced_widgets": [
      "1b2ccfe9434b4098a192c1af655fd381",
      "1eba34f7a0c640f88001ad28d5da660d",
      "a452d2d13a52465198b374b2f0c6c1b4",
      "872d8636eb934b06af9b893d9d4e6da3",
      "e9ae828c3f0c4bee989b4f17d1ef41ed",
      "7ec9551cd4da44518b5e968c8f70ce95",
      "a51ed338273341cfa8acf725044ec656",
      "0838bf73f248456ebe7e435bd8faa606"
     ]
    },
    "colab_type": "code",
    "id": "AK-oBlDS-z59",
    "outputId": "9fe91890-eee2-4c57-a459-eba2920188a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b2ccfe9434b4098a192c1af655fd381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "TEST RESULTS\n",
      "{'avg_test_bleu': 19.734138788503238}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ooF3sg9vqGcj"
   },
   "source": [
    "#Salvando os resultados em um .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iN8Go1TRsqaO"
   },
   "outputs": [],
   "source": [
    "compression_opts = dict(method='zip', archive_name='enpt_t5_results.csv') \n",
    "model.df_test.to_csv('enpt_t5_results.zip', index=False,compression=compression_opts)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NoCas0ynqXtJ"
   },
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fOxcC1xnGGO2"
   },
   "source": [
    "* Nucleous sampling não é bom para tradução, recomendado a usar greedy search ou beam search\n",
    "* Vale a pena treinar até 3 épocas\n",
    "* Usar o truque dos ascentos do Alexandre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HPfpCGKHqZuD"
   },
   "source": [
    "# Fim do Notebook"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Aula9_T5_PortEng_Translator.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00af6e41422d4d138cbd5c67038339ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "00cface36bcb4a5c8450b9dc0457d5f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cc48d01a43b4d5280ac8966375ec6cf",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a21300fb32254fae914de74371e82951",
      "value": 1
     }
    },
    "02eeb3f2accf42a9a7581215cf8c3933": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7a2fb72523a94eba986ae0b8441a21c6",
       "IPY_MODEL_6416cc0a86a742ec85a6aac205a5b480"
      ],
      "layout": "IPY_MODEL_6c765ad902a046b7b3d0b3440ccccf12"
     }
    },
    "058e6ba13fab4eb29f1b830391b981dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0838bf73f248456ebe7e435bd8faa606": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b4df8d14cbf482292a02aa81e8d2f66": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfee76d204384008bd36a42bff7c0e0d",
       "IPY_MODEL_50911aecd9274e8295903bbe488174b1"
      ],
      "layout": "IPY_MODEL_535354ff470242bf8aaaf087c27806b1"
     }
    },
    "0d41d0a6e38d4593943ff061807e40d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0d926a40b9ad4fbab0219962cc42b10a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59db0d5b0493455b8c97b5226cd09cdd",
      "placeholder": "​",
      "style": "IPY_MODEL_c604ffb933d04f10858a304766950843",
      "value": " 1/1 [05:38&lt;00:00, 338.46s/it]"
     }
    },
    "0ed175e00fb040199221454484c2ce36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c5c33a4a56a4635aeb34ad58fac28ad",
       "IPY_MODEL_fb69c3051eed413095b8b37dfa9f709a"
      ],
      "layout": "IPY_MODEL_1853255b8dbb43c9a1b6586c8ded37eb"
     }
    },
    "1529dba528b542ce9960eda75d46ad96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ab0448670ef84ef38b63ab986f3b0bb9",
       "IPY_MODEL_4cc15c30f78b42caa7c1b40d5e687450"
      ],
      "layout": "IPY_MODEL_d22ccd5f2b4d45b0b8b5619040d59b57"
     }
    },
    "1853255b8dbb43c9a1b6586c8ded37eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "1a56ca60f6d941869c470d70b650655b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43455503fbcb40989b553a992881f6e3",
       "IPY_MODEL_a6de18ac16d64e7192318f493cfb7706"
      ],
      "layout": "IPY_MODEL_afdf8049dcdc44fb88eddcb142a0e96b"
     }
    },
    "1b2ccfe9434b4098a192c1af655fd381": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a452d2d13a52465198b374b2f0c6c1b4",
       "IPY_MODEL_872d8636eb934b06af9b893d9d4e6da3"
      ],
      "layout": "IPY_MODEL_1eba34f7a0c640f88001ad28d5da660d"
     }
    },
    "1be21389a0674fc994ee3f954b052c89": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d3322cb394d41d6b5e6cf3b77777732": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_637927947f1d4821ba6773d02c5e5c77",
      "placeholder": "​",
      "style": "IPY_MODEL_919c55aa170d4d9a9a46732f355009df",
      "value": " 0/? [00:00&lt;?, ?it/s]"
     }
    },
    "1eba34f7a0c640f88001ad28d5da660d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "24a70bdb9f6e4e27b4fddf51d22e91ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2ac3120b5ca420ca65943fe13104b78",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e195b449d0db42468a235afc8bad8913",
      "value": 1
     }
    },
    "25eda07be1d1480d8029f126d2b257a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_24a70bdb9f6e4e27b4fddf51d22e91ea",
       "IPY_MODEL_e69b9a611355430880320753f6c79a83"
      ],
      "layout": "IPY_MODEL_5b71736916264afa9af47d64cc78bc61"
     }
    },
    "270e6f274e31485fadc0f901a5f9586c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "2c2860c52b794dd381bf935b9004bee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2c7bc0cbcf3641daad406d35d5cf1146": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "2e48c5d32723497db817d029dd731d75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3386da8ca76c40e7814ae179bfc86319": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "343b49f95dd0437ea80102092469017c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch 1: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92911b01ad6f4e618b87ead4444fd840",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_058e6ba13fab4eb29f1b830391b981dd",
      "value": 2
     }
    },
    "3b9e2640ff584b9aa479ffcb9e4537f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ec8f393dfde44798a9ea2fdbb0e32c36",
       "IPY_MODEL_1d3322cb394d41d6b5e6cf3b77777732"
      ],
      "layout": "IPY_MODEL_270e6f274e31485fadc0f901a5f9586c"
     }
    },
    "3efb59b711cd4c98bb8afb62988d57b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6913d040ed54329acf907275010feb7",
      "placeholder": "​",
      "style": "IPY_MODEL_9d715f95de4048e5943c23f2fd67fd47",
      "value": " 62/62 [00:54&lt;00:00,  1.13it/s]"
     }
    },
    "43455503fbcb40989b553a992881f6e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Testing: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd97557e76874f06a0a01213cea95032",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c2860c52b794dd381bf935b9004bee9",
      "value": 1
     }
    },
    "47299bc0a61f428e944a217e50606eb5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "499e4cf91ef3419e91f5b38b70f63246": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3ca94ebdd97489e8c36d21f2d0ac83b",
      "placeholder": "​",
      "style": "IPY_MODEL_58115f14ec9948de9bd6f7d277452252",
      "value": " 2/2 [05:44&lt;00:00, 172.03s/it, avg_val_bleu=0, cpu=36.7%, gpu=9%, gpu_mem=1%, loss=8.909, mem=24.6%, v_num=7]"
     }
    },
    "4cc15c30f78b42caa7c1b40d5e687450": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a0eed9192a5440880ae2554a4bc41f6",
      "placeholder": "​",
      "style": "IPY_MODEL_d040f2d40b0b4b9bac795e0c108dcb04",
      "value": " 5/5 [00:04&lt;00:00,  1.09it/s]"
     }
    },
    "4dcd98df7ce349af8d8aa7e77c9e9ca0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50911aecd9274e8295903bbe488174b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebf3bcdbf9b34df4b56e519fdf423606",
      "placeholder": "​",
      "style": "IPY_MODEL_925f96aad8234eb7864a5a4c351120f9",
      "value": " 0/5 [00:22&lt;?, ?it/s]"
     }
    },
    "535354ff470242bf8aaaf087c27806b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "58115f14ec9948de9bd6f7d277452252": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59db0d5b0493455b8c97b5226cd09cdd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "59df790c53f94047b49f5a08b4eaff4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d150607ab5ac48f380d8e0ddba0d0c5c",
      "placeholder": "​",
      "style": "IPY_MODEL_6935e20239f0436db3fd3f94a697df35",
      "value": " 62/62 [00:54&lt;00:00,  1.13it/s]"
     }
    },
    "5b1a47e76ee744caba0555b7ef0f95b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b71736916264afa9af47d64cc78bc61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "614ddfd9f7d748829143cde3cf43f043": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "63552451ca7a431b8f35e3943f2079ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "637927947f1d4821ba6773d02c5e5c77": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6416cc0a86a742ec85a6aac205a5b480": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c116be289b384886a95de435d8a9d6ea",
      "placeholder": "​",
      "style": "IPY_MODEL_968ab69b521c4b09b4448c5cda99a9e9",
      "value": " 124/124 [13:41&lt;00:00,  6.62s/it, avg_val_bleu=63.9, cpu=59.0%, gpu=97%, gpu_mem=73%, loss=0.026, mem=25.0%, v_num=1]"
     }
    },
    "685f8fb69ba44132896dda7c856669ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "6935e20239f0436db3fd3f94a697df35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c765ad902a046b7b3d0b3440ccccf12": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "739af17beb2444c48b76dd9caee0a35c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_343b49f95dd0437ea80102092469017c",
       "IPY_MODEL_499e4cf91ef3419e91f5b38b70f63246"
      ],
      "layout": "IPY_MODEL_d3b42130b298455a906c23b594fa4893"
     }
    },
    "75ff9af7225e4a9592ee3282cb3191f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c191ebf5cf8b4a3485244cb500b5d711",
       "IPY_MODEL_0d926a40b9ad4fbab0219962cc42b10a"
      ],
      "layout": "IPY_MODEL_2c7bc0cbcf3641daad406d35d5cf1146"
     }
    },
    "77b9502293e54a059640adebc044aaf6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "79bff1036b1b4a77b8f94af6f9b24e8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7a2fb72523a94eba986ae0b8441a21c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch 30: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63552451ca7a431b8f35e3943f2079ad",
      "max": 124,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5852d39a93e470cbca4482b524e5feb",
      "value": 124
     }
    },
    "7afbb4c50a21436085a25f49bac80c88": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c5c33a4a56a4635aeb34ad58fac28ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4dcd98df7ce349af8d8aa7e77c9e9ca0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3386da8ca76c40e7814ae179bfc86319",
      "value": 1
     }
    },
    "7d615c8423174f3b8bcb9870936adf2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_00cface36bcb4a5c8450b9dc0457d5f4",
       "IPY_MODEL_59df790c53f94047b49f5a08b4eaff4d"
      ],
      "layout": "IPY_MODEL_df6114e28226459199e5b54cd36fbb5c"
     }
    },
    "7ec9551cd4da44518b5e968c8f70ce95": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80d361cd69ca4d7aa4b313c0e824e66d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validating: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1be21389a0674fc994ee3f954b052c89",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d41d0a6e38d4593943ff061807e40d1",
      "value": 1
     }
    },
    "872d8636eb934b06af9b893d9d4e6da3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0838bf73f248456ebe7e435bd8faa606",
      "placeholder": "​",
      "style": "IPY_MODEL_a51ed338273341cfa8acf725044ec656",
      "value": " 1230/1250 [1:28:01&lt;01:25,  4.29s/it]"
     }
    },
    "8cc48d01a43b4d5280ac8966375ec6cf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "907d4431dc634e9da33db98818711ac7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "919c55aa170d4d9a9a46732f355009df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "925f96aad8234eb7864a5a4c351120f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92911b01ad6f4e618b87ead4444fd840": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "968ab69b521c4b09b4448c5cda99a9e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a0eed9192a5440880ae2554a4bc41f6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d715f95de4048e5943c23f2fd67fd47": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a21300fb32254fae914de74371e82951": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a452d2d13a52465198b374b2f0c6c1b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "Testing:  98%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ec9551cd4da44518b5e968c8f70ce95",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9ae828c3f0c4bee989b4f17d1ef41ed",
      "value": 1
     }
    },
    "a51ed338273341cfa8acf725044ec656": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6de18ac16d64e7192318f493cfb7706": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_907d4431dc634e9da33db98818711ac7",
      "placeholder": "​",
      "style": "IPY_MODEL_00af6e41422d4d138cbd5c67038339ae",
      "value": " 62/62 [12:34&lt;00:00, 12.16s/it]"
     }
    },
    "ab0448670ef84ef38b63ab986f3b0bb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "Validation sanity check: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c3854aee523542298f2586e298e563d1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_614ddfd9f7d748829143cde3cf43f043",
      "value": 1
     }
    },
    "ad90ede6b7384ff2ae467a2e4b35f2b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afdf8049dcdc44fb88eddcb142a0e96b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "b2ac3120b5ca420ca65943fe13104b78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6ad1cf50b6d4ffd867f51a0fe177668": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c116be289b384886a95de435d8a9d6ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c191ebf5cf8b4a3485244cb500b5d711": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Testing: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_47299bc0a61f428e944a217e50606eb5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_685f8fb69ba44132896dda7c856669ce",
      "value": 1
     }
    },
    "c3854aee523542298f2586e298e563d1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c604ffb933d04f10858a304766950843": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfee76d204384008bd36a42bff7c0e0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "Validation sanity check:   0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed2194a6a9b34d24977087ff9cb281e9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79bff1036b1b4a77b8f94af6f9b24e8a",
      "value": 0
     }
    },
    "d040f2d40b0b4b9bac795e0c108dcb04": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d150607ab5ac48f380d8e0ddba0d0c5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d22ccd5f2b4d45b0b8b5619040d59b57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "d3b42130b298455a906c23b594fa4893": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "d473c55ed0a84501908ce502601b3da5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_80d361cd69ca4d7aa4b313c0e824e66d",
       "IPY_MODEL_3efb59b711cd4c98bb8afb62988d57b8"
      ],
      "layout": "IPY_MODEL_77b9502293e54a059640adebc044aaf6"
     }
    },
    "df6114e28226459199e5b54cd36fbb5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "e195b449d0db42468a235afc8bad8913": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e6913d040ed54329acf907275010feb7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e69b9a611355430880320753f6c79a83": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad90ede6b7384ff2ae467a2e4b35f2b9",
      "placeholder": "​",
      "style": "IPY_MODEL_2e48c5d32723497db817d029dd731d75",
      "value": " 1/1 [00:05&lt;00:00,  5.15s/it]"
     }
    },
    "e9ae828c3f0c4bee989b4f17d1ef41ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ebf3bcdbf9b34df4b56e519fdf423606": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec8f393dfde44798a9ea2fdbb0e32c36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Training: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7afbb4c50a21436085a25f49bac80c88",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f4226b9f12394b8a8b32c8dd6a3ea5dc",
      "value": 0
     }
    },
    "ed2194a6a9b34d24977087ff9cb281e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3ca94ebdd97489e8c36d21f2d0ac83b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4226b9f12394b8a8b32c8dd6a3ea5dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f5852d39a93e470cbca4482b524e5feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fb69c3051eed413095b8b37dfa9f709a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b1a47e76ee744caba0555b7ef0f95b8",
      "placeholder": "​",
      "style": "IPY_MODEL_b6ad1cf50b6d4ffd867f51a0fe177668",
      "value": " 62/62 [00:54&lt;00:00,  1.16it/s]"
     }
    },
    "fd97557e76874f06a0a01213cea95032": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
